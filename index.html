<html><head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
<title>Nikhil R. Devanur</title>
</head>
<body leftmargin="10" topmargin="10" vlink="#3366ff" alink="#3366ff" background="files/bg_grid_white.gif" link="#3366ff" marginheight="10" marginwidth="10" text="#000000">
<style type="text/css">
<!--

A:link{text-decoration: underline; color: #000000; font-weight: bold;}
A:visited{text-decoration: underline; color: #000000; font-weight: bold;}
A:active{text-decoration: underline; color: #ff0000; font-weight: bold;}
A:hover{text-decoration: underline; color: #ff0000; font-weight: bold;}



.NVerdana {font-family: verdana; font-size: 10pt}
.NArial   {font-family: arial; font-size: 10pt}
.NArialL  {font-family: arial; font-size: 12pt}
.NArialS  {font-family: arial; font-size: 8pt}
.NArialW  {COLOR: #FFFFFF; font-family: arial; font-size: 10pt}

-->
</style>
<script type="text/javascript">
<!--
    function toggle_visibility(id) {
       var e = document.getElementById(id);
       if(e.style.display == 'block')
          e.style.display = 'none';
       else
          e.style.display = 'block';
    }
//-->
</script>
<div align="left">
<table width="1000" border="0" cellpadding="1" cellspacing="0">

<tbody><tr><td>
<table width="70" border="0" cellpadding="0" cellspacing="0">
<tbody><tr><td width="100%">
</td> </tr></tbody></table> </td>
<td>
          <table height="20"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

</td></tr><tr> <td>

<table width="100%" bgcolor="#dbeaf5" border="0" cellpadding="5" cellspacing="0">

<tbody><tr><td>
<font face="Arial" size="+2"> Nikhil R Devanur </font>
</td>

</tr></tbody></table>

          <table height="30"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

<table>
<tbody><tr> <td width="40%" align="center"> <img src="files/Profile2019.jpg">
</td><td> <font face="Trebuchet MS" size="3">


<table height="20"> <tbody><tr><td width="100%"> </td></tr></tbody></table>
 <font face="Trebuchet MS" size="3">
 	Bio: Nikhil R. Devanur is the manager of the <a href="https://www.microsoft.com/en-us/research/group/algorithms-redmond/" >Algorithms group</a>
  in <a href="http://research.microsoft.com/" >Microsoft Research</a>, Redmond.
He is interested in what he calls  <IT> Automated Economics, <IT> which studies the question of how
technology can be used to improve the efficiency of economic systems.
His other interest is in <it> Algorithms<it>: he is interested in designing algorithms that are faster, simpler,
work online or in a distributed fashion, for some of the basic combinatorial optimization problems.

  <p>
  Contact: Iam@nikhildevanur.com
  </p>
<!-- 	  Part of my research focuses around various computational issues in economics and game theory, -->
<!-- especially computing market equilibrum. Part of it focuses on the design and -->
<!-- analysis of efficient  algorithms for combinatorial optimization problems. -->



     <table height="20"> <tbody><tr><td width="100%"> </td></tr></tbody></table>
     Mentees (Interns)
     <ul>
     	<li> Ben Birnbaum, Flatiron Healrh</li>
     	<li> <a href = "http://pages.cs.wisc.edu/~balu2901/"> Balu Sivan,  </a> Google Research</li>
     	 <li> <a href = "http://i.cs.hku.hk/~zhiyi/"> Zhiyi Huang, </a>  University of Hong Kong </li>
     	<li> <a href = "http://jamiemorgenstern.com/"> Jamie Morgenstern, </a>  Georgia Tech </li>
     	<li> <a href = "https://www.microsoft.com/en-us/research/people/jakul/"> Janardhan Kulkarni,</a> Microsoft Research  </li>
     	<li> <a href = "http://www.cs.cmu.edu/~cpsomas/"> Alex Psomas,</a>  CMU </li>
         <li> <a href = "http://www.cs.cornell.edu/~rad/" > Rad Niazadeh,</a> Stanford</li>
         <li> <a href = "http://www.cc.gatech.edu/~syazdanb/"> Sadra Yazdanbod,</a> Google</li>
         <li> <a href = "http://homes.cs.washington.edu/~kgoldner/"> Kira Goldner,</a> University of Washington</li>
         <li> <a href = "http://www.cs.cornell.edu/~teddlyk/"> Thodoris Lykouris,</a> Cornell University</li>
         <li> <a href = "http://jakub.tarnawski.org/"> Jakub Tarnawski,</a> EPFL</li>

     </ul>

     </td>
</tr>
</tbody></table>

 <div align="left">
	<table height="30"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

	<table width="100%" bgcolor="#dbeaf5" border="0" cellpadding="5" cellspacing="0">
		<tbody><tr><td align="left">
					<font face="Arial" size="+1"> <a name="pubselect"> News </a> </font>
				</td>
			</font></td></tr></tbody></table>


<ul>
	<font face="Trebuchet MS" size="3">
        <li> Spring 2019: We are hiring! Please <a href = " https://www.microsoft.com/en-us/research/group/algorithms-redmond/#!opportunities" > apply</a>.
        <li> Spring 2017:  I now manage the newly created <a href="https://www.microsoft.com/en-us/research/group/algorithms-redmond/" >Algorithms group</a> in Micrsoft Research, Redmond. </li>
<li> I am co-teaching (with Anna Karlin) a <a href = https://courses.cs.washington.edu/courses/cse522/17sp/> course on Algorithms and Uncertainty  </a> at UW this spring quarter, 2017.

<li>  I am the co-Program Committee Chair of <a href = "http://lcm.csa.iisc.ernet.in/wine2017/" > WINE 2017. </a>
	<!-- Deadline to submit has passed. T</P> -->
<li>   I am organizing an <a href="http://wecc.azurewebsites.net/"> ACM EC Workshop on Economic Aspects of Cloud Computing</a>. Submission deadline is May 17th, 2016.

<li>  I am the Program Committee Chair of <a href = "http://cui.unige.ch/tcs/random-approx/2014/index.php" > APPROX 2014 </a>.
	<!-- Deadline to submit has passed. The list of accepted papers will be out on June 7th.


		<p>
		I am part of the team that is running a <a href = "http://msrindianelections.com" > prediction market for
		Indian elections, 2014 </a>. Do try it out if you are interested in these elections or in prediction markets.  -->

		<li>
		I organized a <a href = https://sites.google.com/site/onlinematchingstoc/home> workshop on Online matching at STOC </a> in Palo Alto on June 1st 2013.

		<li>
		I gave a tutorial  on <a href = http://www.sigecom.org/ec13/schedule_tutorials.html> Prior-Robust Optimization at EC </a> in Philadelphia on June 16 2013.

		<li>
		I taught  a <a href = OnlineAlgoCourse/index1.html> course on online algorithms </a> at UW this winter quarter, 2013.

</ul>
</font></font></td></tr></tbody></table>


 <div align="left">
          <table height="30"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

<table width="100%" bgcolor="#dbeaf5" border="0" cellpadding="5" cellspacing="0">
<tbody><tr><td align="left">
<font face="Arial" size="+1"> <a name="pubselect"> Manuscripts </a> </font>
 </td>
</font></td></tr></tbody></table>

<ul>
<font face="Trebuchet MS" size="3">

<!--
<li> <b> ***  </b>
[<a href="pubs/***.pdf">pdf</a>| <a   href = "#CP" onclick="toggle_visibility('abs***');">Show/Hide  Abstract</a>]
<br> with ***.
In Proc.
<i>  ***  </i>
<div id="abs***" style="display:none"><font face="Arial" size="3">
<p>
***
</p>
 </font></div></li>
-->



<li> <b> A new auction format for IPL players auctions</b>
[<a href="pubs/IPLDraftAuctionsv3.1.pdf">pdf</a>].
 </li>




<li>
<a href = "http://www.informatik.uni-trier.de/~ley/pers/hd/d/Devanur:Nikhil_R=" target="_blank" > DBLP page </a>
 </li>

<li>
<a href = "https://arxiv.org/search/?query=nikhil+devanur&searchtype=author&abstracts=hide&order=-announced_date_first&size=50" target="_blank" > Papers on Arxiv </a>
 </li>


</ul>
<div align="left">
          <table height="30"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

<table width="100%" bgcolor="#dbeaf5" border="0" cellpadding="5" cellspacing="0">
<tbody><tr><td align="left">
<font face="Arial" size="+1"> <a name="pubselect"> Selected Recent  Publications </a> </font>
 </td>
<!-- <td align="right">
<font face="Trebuchet MS" size="3">
Arrange by  <a href="index-area.html">Area</a>
   <!--|  <a href="index-area.html/#pubdate">Date</a> ]
</font></td> -->
</tr></tbody></table>
<font face="Trebuchet MS" size="3">
<!-------------------------------------------------------------->
<b>2018</b> <ul>
<!-------------------------------------------------------------->
<li> <b>
		A New Class of Combinatorial Markets with Covering Constraints: Algorithms and Applications  </b>
	[<a href="https://arxiv.org/pdf/1511.08748.pdf">arXiv pdf</a>| <a   href = "#CME" onclick="toggle_visibility('absCME');">Show/Hide  Abstract</a>].
	<br> with Jugal Garg, Ruta Mehta, Vijay V. Vazirani, Sadra Yazdanbod.
			In Proc. <i>SODA 2018</i>.
		<div id="absCME" style="display:none"><font face="Arial" size="3">
				<p>
					We introduce a new class of combinatorial markets in which agents have covering constraints over resources required and are interested in delay minimization. Our market model is applicable to several settings including scheduling, cloud computing, and communicating over a network. This model is quite different from the traditional models, to the extent that neither do the classical equilibrium existence results seem to apply to it nor do any of the efficient algorithmic techniques developed to compute equilibria seem to apply directly. We give a proof of existence of equilibrium and a polynomial time algorithm for finding one, drawing heavily on techniques from LP duality and submodular minimization. We observe that in our market model, the set of equilibrium prices could be a connected, non-convex set. To the best of our knowledge, this is the first natural example of the phenomenon where the set of solutions could have such complicated structure, yet there is a combinatorial polynomial time algorithm to find one. Finally, we show that our model inherits many of the fairness properties of traditional equilibrium models.
				</p>
			</font></div>
	</li>

	<li> <b>
			Truthful Multi-Parameter Auctions with Online Supply: an Impossible Combination </b>
		[<a href="https://arxiv.org/pdf/1511.03699.pdf">arXiv pdf</a>| <a   href = "#TMOA" onclick="toggle_visibility('absTMOA');">Show/Hide  Abstract</a>].
		<br> with Balasubramanian Sivan and Vasilis Syrgkanis.
			In Proc. <i>SODA 2018</i>.
			<div id="absTMOA" style="display:none"><font face="Arial" size="3">
					<p>
						We study a basic auction design problem with online supply. There are two unit-demand bidders and two types of items. The first item type will arrive first for sure, and the second item type may or may not arrive. The auctioneer has to decide the allocation of an item immediately after each item arrives, but is allowed to compute payments after knowing how many items arrived. For this problem we show that there is no deterministic truthful and individually rational mechanism that, even with unbounded computational resources, gets any finite approximation factor to the optimal social welfare.
					</p>
				</font></div>
		</li>


	<li> <b>
		Bubble Execution: Resource-aware Reliable Analytics at Cloud Scale.  </b>
			[<a href="pubs/Bubble_with_ack.pdf">pdf</a>| <a   href = "#BE" onclick="toggle_visibility('absBE');">Show/Hide  Abstract</a>].
		<br> with 		Zhicheng Yin, Jin Sun, Ming Li, Jaliya Ekanayake, Haibo Lin, Marc Friedman, Jose A. Blakeley and Clemens A. Szyperski.
			In Proc. <i>VLDB 2018</i>.
			<div id="absBE" style="display:none"><font face="Arial" size="3">
					<p>
						Enabling interactive data exploration at cloud scale requires
						minimizing end-to-end query execution latency, while guar-
						anteeing fault tolerance, and query execution under resource-
						constraints. Typically, such a query execution involves or-
						chestrating the execution of hundreds or thousands of re-
						lated tasks on cloud scale clusters. Without any resource
						constraints, all query tasks can be scheduled to execute si-
						multaneously (gang scheduling) while connected tasks stream
						data between them. When the data size referenced by a
						query increases, gang scheduling may be resource-wasteful
						or un-satisﬁable with a limited, per-query resource budget.
						This paper introduces Bubble Execution, a new query
						processing framework for interactive workloads at cloud scale,
						that balances cost-based query optimization, fault tolerance,
						optimal resource management, and execution orchestration.
						Bubble execution involves dividing a query execution graph
						into a collection of query sub-graphs (bubbles), and scheduling them within a per-query resource budget. The query
						operators (tasks) inside a bubble stream data between them
						while fault tolerance is handled by persisting temporary results at bubble boundaries. Our implementation enhances
						our JetScope service, for interactive workloads, deployed in
						production clusters at Microsoft. Experiments with TPC-H
						queries show that bubble execution can reduce resource usage significantly in the presence of failures while maintaining
						performance competitive with gang execution.
					</p>
				</font></div>
		</li>

</ul>


<!-------------------------------------------------------------->
<b>2017</b> <ul>
<!-------------------------------------------------------------->

    <li> <b> Stability of Service under Time-of-Use Pricing</b>
			[<a href="https://arxiv.org/pdf/1704.02364.pdf"> arXiv pdf </a>|     <a   href = "#SOS" onclick="toggle_visibility('absSOS');">Show/Hide  Abstract</a>]
			<br> with  Shuchi Chawla, Alexander E. Holroyd, Anna Karlin, James Martin and Balasubramanian Sivan.
				In Proc. <i>STOC 2017</i>
				<div id="absSOS" style="display:none"><font face="Arial" size="3">
						<p>
                            We consider "time-of-use" pricing as a technique for matching supply and demand of temporal resources with the goal of maximizing social welfare. Relevant examples include energy, computing resources on a cloud computing platform, and charging stations for electric vehicles, among many others. A client/job in this setting has a window of time during which he needs service, and a particular value for obtaining it. We assume a stochastic model for demand, where each job materializes with some probability via an independent Bernoulli trial. Given a per-time-unit pricing of resources, any realized job will first try to get served by the cheapest available resource in its window and, failing that, will try to find service at the next cheapest available resource, and so on. Thus, the natural stochastic fluctuations in demand have the potential to lead to cascading overload events. Our main result shows that setting prices so as to optimally handle the <it> expected </it> demand works well: with high probability, when the actual demand is instantiated, the system is stable and the expected value of the jobs served is very close to that of the optimal offline algorithm.
						</p>
					</font></div></li>


    <li> <b> Truth and Regret in Online Scheduling</b>
			[<a href="https://arxiv.org/pdf/1703.00484.pdf"> arXiv pdf </a>|     <a   href = "#TROS" onclick="toggle_visibility('absTROS');">Show/Hide  Abstract</a>]
			<br> with   Shuchi Chawla, Janardhan Kulkarni, Rad Niazadeh.
				In Proc. <i>EC 2017</i>
				<div id="absTROS" style="display:none"><font face="Arial" size="3">
						<p>
                            We consider a scheduling problem where a cloud service provider has multiple units of a resource available over time. Selfish clients submit jobs, each with an arrival time, deadline, length, and value. The service provider's goal is to implement a truthful online mechanism for scheduling jobs so as to maximize the social welfare of the schedule. Recent work shows that under a stochastic assumption on job arrivals, there is a single-parameter family of mechanisms that achieves near-optimal social welfare. We show that given any such family of near-optimal online mechanisms, there exists an online mechanism that in the worst case performs nearly as well as the best of the given mechanisms. Our mechanism is truthful whenever the mechanisms in the given family are truthful and prompt, and achieves optimal (within constant factors) regret.
We model the problem of competing against a family of online scheduling mechanisms as one of learning from expert advice. A primary challenge is that any scheduling decisions we make affect not only the payoff at the current step, but also the resource availability and payoffs in future steps. Furthermore, switching from one algorithm (a.k.a. expert) to another in an online fashion is challenging both because it requires synchronization with the state of the latter algorithm as well as because it affects the incentive structure of the algorithms. We further show how to adapt our algorithm to a non-clairvoyant setting where job lengths are unknown until jobs are run to completion. Once again, in this setting, we obtain truthfulness along with asymptotically optimal regret (within poly-logarithmic factors).

						</p>
					</font></div></li>


     <li> <b>
	Convex Program Duality, Fisher Markets, and Nash Social Welfare
	</b>[<a href="https://arxiv.org/pdf/1609.06654.pdf">arXiv pdf</a> | <a   href = "#CP" onclick="toggle_visibility('absCP');">Show/Hide  Abstract</a>].
	<br> with  Richard Cole,  Vasilis Gkatzelis, Kamal Jain, Tung Mai, Vijay V. Vazirani and Sadra Yazdanbod.
		In Proc. <i>EC 2017</i>
         <div id="absCP" style="display:none"><font face="Arial" size="3">
				<p>
					We study Fisher markets and the problem of maximizing the Nash social welfare (NSW), and show several closely related new results. In particular, we obtain:
                    <ul>
                        <li> A new integer program for the NSW maximization problem whose fractional relaxation has a bounded integrality gap. In contrast, the natural integer program has an unbounded integrality gap. </li>
                        <li> An improved, and tight, factor 2 analysis of the algorithm of [7]; in turn showing that the integrality gap of the above relaxation is at most 2. The approximation factor shown by [7] was 2e^(1/e) ~ 2.89. </li>
                        <li> A lower bound of e^(1/e) ~ 1.44 on the integrality gap of this relaxation. </li>
                        <li> New convex programs for natural generalizations of linear Fisher markets and proofs that these markets admit rational equilibria. </li>
            </ul>
            These results were obtained by establishing connections between previously known disparate results, and they help uncover their mathematical underpinnings. We show a formal connection between the convex programs of Eisenberg and Gale and that of Shmyrev, namely that their duals are equivalent up to a change of variables. Both programs capture equilibria of linear Fisher markets. By adding suitable constraints to Shmyrev's program, we obtain a convex program that captures equilibria of the spending-restricted market model defined by [7] in the context of the NSW maximization problem. Further, adding certain integral constraints to this program we get the integer program for the NSW mentioned above.
The basic tool we use is convex programming duality. In the special case of convex programs with linear constraints (but convex objectives), we show a particularly simple way of obtaining dual programs, putting it almost at par with linear program duality. This simple way of finding duals has been used subsequently for many other applications.
				</p>
			</font></div></li>

    <li> <b> Optimal Multi-Unit Mechanisms with Private Demands</b>
			[<a href="https://arxiv.org/pdf/1704.05027.pdf"> arXiv pdf </a>|     <a   href = "#MUP" onclick="toggle_visibility('absMUP');">Show/Hide  Abstract</a>]
			<br> with   Nima Haghpanah, Christos-Alexandros Psomas.
				In Proc. <i>EC 2017</i>
				<div id="absMUP" style="display:none"><font face="Arial" size="3">
						<p>
                            In the multi-unit pricing problem, multiple units of a single item are for sale. A buyer's valuation for n units of the item is v*min{n,d}, where the per unit valuation v and the capacity d are private information of the buyer. We consider this problem in the Bayesian setting, where the pair (v,d) is drawn jointly from a given probability distribution. In the unlimited supply setting, the optimal (revenue maximizing) mechanism is a pricing problem, i.e., it is a menu of lotteries. In this paper we show that under a natural regularity condition on the probability distributions, which we call decreasing marginal revenue, the optimal pricing is in fact deterministic. It is a price curve, offering i units of the item for a price of p_i, for every integer i. Further, we show that the revenue as a function of the prices p_i is a concave function, which implies that the optimum price curve can be found in polynomial time. This gives a rare example of a natural multi-parameter setting where we can show such a clean characterization of the optimal mechanism. We also give a more detailed characterization of the optimal prices for the case where there are only two possible demands.
						</p>
					</font></div></li>


    <li> <b> Online Auctions and Multi-scale Online Learning</b>
			[
        <a href="pubs/msol-jmlr.pdf">  pdf </a>|
        <a   href = "#MSOL" onclick="toggle_visibility('absMSOL');">Show/Hide  Abstract</a>]
			<br> with  Sebastien Bubeck, Zhiyi Huang and Rad Niazadeh.
				In Proc. <i>EC 2017</i>
				<div id="absMSOL" style="display:none"><font face="Arial" size="3">
						<p>
                           We consider revenue maximization in online auctions and pricing. A seller sells an identical item in each
period to a new buyer, or a new set of buyers. For the online posted pricing problem, we show regret bounds
that scale with the best fixed price, rather than the range of the values. We also show regret bounds that are
almost scale free, and match the offine sample complexity, when comparing to a benchmark that requires a
lower bound on the market share. These results are obtained by generalizing the classical learning from experts
and multi-armed bandit problems to their multi-scale versions. In this version, the reward of each action is in
a different range, and the regret w.r.t. a given action scales with its own range, rather than the maximum range.
						</p>
					</font></div></li>

    <li> <b> The optimal mechanism for selling to a budget constrained buyer: the general case</b>
			[
        <a href="pubs/sib-ec.pdf"> pdf </a>|
        <a   href = "#SIB" onclick="toggle_visibility('absSIB');">Show/Hide  Abstract</a>]
			<br> with  Matt  Weinberg.
				In Proc. <i>EC 2017</i>
				<div id="absSIB" style="display:none"><font face="Arial" size="3">
						<p>
                           We consider a revenue-maximizing seller with a single item facing a single buyer with a private budget. The (value, budget) pair is drawn from an arbitrary and possibly correlated distribution. We characterize the
optimal mechanism in such cases, and quantify the amount of price discrimination that might be present. For
example, there could be up to 3*2^(k-1)-1 distinct non-trivial menu options in the optimal mechanism for such
a buyer with k distinct possible budgets (compared to k if the marginal distribution of values conditioned on
each budget has decreasing marginal revenue [Che and Gale, 2000], or 2 if there is an arbitrary distribution
and one possible budget [Chawla et al., 2011]).

Our approach makes use of the duality framework of Cai et al. [2016], and duality techniques related to the
"FedEx Problem" of Fiat et al. [2016]. In contrast to [Fiat et al., 2016] and other prior work, we characterize the
optimal primal/dual without nailing down an explicit closed form.
						</p>
					</font></div></li>


</ul>


<!-------------------------------------------------------------->
<b>2016</b> <ul>
<!-------------------------------------------------------------->



    <li> <b> Linear Contextual Bandits with Knapsacks</b>
			[<a href="pubs/NIPSLinContextualmain.pdf"> NIPS pdf </a>|  <a href= "pubs/NIPSLinContextualSupplement.pdf" > Supplement </a>   |    <a   href = "#LCB" onclick="toggle_visibility('absLCB');">Show/Hide  Abstract</a>]
			<br> with  Shipra Agrawal.
				In Proc. <i>NIPS 2016</i>
				<div id="absLCB" style="display:none"><font face="Arial" size="3">
						<p>
							We consider the linear contextual bandit problem with resource consumption, in
addition to reward generation. In each round, the outcome of pulling an arm is
a reward as well as a vector of resource consumptions. The expected values of
these outcomes depend linearly on the context of that arm. The budget/capacity
constraints require that the total consumption doesn’t exceed the budget for each
resource. The objective is once again to maximize the total reward. This problem
turns out to be a common generalization of classic linear contextual bandits (linContextual), bandits with knapsacks (BwK), and the online stochastic
packing problem (OSPP). We present algorithms with near-optimal regret
bounds for this problem. Our bounds compare favorably to results on the unstruc-
tured version of the problem where the relation between the contexts and
the outcomes could be arbitrary, but the algorithm only competes against a ﬁxed
set of policies accessible through an optimization oracle. We combine techniques
from the work on linContextual, BwK and OSPP in a nontrivial manner while also
tackling new difﬁculties that are not present in any of these special cases.
						</p>
					</font></div></li>

		<li> <b>The Sample Complexity of Auctions with Side Information</b>
			[<a href="http://arxiv.org/pdf/1511.02296.pdf">arXiv pdf</a>| <a   href = "#SCA" onclick="toggle_visibility('absSCA');">Show/Hide  Abstract</a>]
			<br> with  Zhiyi Huang and Christos-Alexandros Psomas.
				In Proc. <i>STOC  2016</i>
				<div id="absSCA" style="display:none"><font face="Arial" size="3">
						<p>
							Traditionally, the Bayesian optimal auction design problem has been considered either when the bidder values are i.i.d, or when each bidder is individually identifiable via her value distribution. The latter is a reasonable approach when the bidders can be classified into a few categories, but there are many instances where the classification of bidders is a continuum. For example, the classification of the bidders may be based on their annual income, their propensity to buy an item based on past behavior, or in the case of ad auctions, the click through rate of their ads. We introduce an alternate model that captures this aspect, where bidders are a priori identical, but can be distinguished based (only) on some side information the auctioneer obtains at the time of the auction. We extend the sample complexity approach of Dhangwatnotai et al. and Cole and Roughgarden to this model and obtain almost matching upper and lower bounds. As an aside, we obtain a revenue monotonicity lemma which may be of independent interest. We also show how to use Empirical Risk Minimization techniques to improve the sample complexity bound of Cole and Roughgarden for the non-identical but independent value distribution case.
						</p>
					</font></div></li>


			<li> <b>A Duality Based Unified Approach to Bayesian Mechanism Design</b>
				[<a href="pubs/DualityAuctions.pdf">pdf</a>| <a   href = "#DBMD" onclick="toggle_visibility('absDBMD');">Show/Hide  Abstract</a>]
				<br> with  Yang Cai and Matt Weinberg.
					In Proc. <i>STOC  2016</i>
					<div id="absDBMD" style="display:none"><font face="Arial" size="3">
							<p>
								We provide a unified view of many recent exciting developments in Bayesian mechanism design, including the black-box reductions of Cai et. al., simple mechanisms for additive buyers [Hart and Nisan, Li and Yao, Babaioff et al.], and posted-price mechanisms for unit-demand buyers [Chawla et al., Kleinberg and Weinberg]. Additionally, we show that viewing these three previously disjoint lines of work through the same lens allows us to improve upon each in several directions. First, our work provides a new and transparent duality framework for Bayesian mechanism design, which naturally accommodates multiple agents, and arbitrary objectives and feasibility constraints. Using this, we prove that either a posted-price mechanism, or the VCG mechanism with per-bidder entry fees is a constant-factor approximation to the optimal Bayesian IC mechanism whenever buyers are unit-demand or additive, unifying previous breakthroughs of Chawla et al. and Yao. In addition, we improve the approximation factor in Yao's work from 69 to 8. Finally, we show that this view also leads to improved structural characterizations in the Cai et. al. framework.
							</p>
						</font></div></li>

	<li> <b>An efficient algorithm for contextual bandits with knapsacks, and an extension to concave objectives</b>
			[<a href="http://arxiv.org/pdf/1506.03374.pdf">arXiv pdf</a>| <a   href = "#CBwK" onclick="toggle_visibility('absCBwK');">Show/Hide  Abstract</a>]
			<br> with  Shipra Agrawal and Lihong Li.
				In Proc. <i>COLT  2016</i>
				<div id="absCBwK" style="display:none"><font face="Arial" size="3">
						<p>
							We consider a contextual version of multi-armed bandit problem with global knapsack constraints.
In each round, the outcome of pulling an arm is a scalar reward and a resource consumption vector, both dependent on the context, and the global knapsack constraints require the total consumption for each resource to be below some pre-fixed budget. The learning agent competes with an arbitrary set of context-dependent policies. This problem was introduced by Badanidiyuru et al., who gave
                            a computationally inefficient algorithm with near optimal regret bounds for it.  We give a <it> computationally efficient </it> algorithm for this problem with slightly better regret bounds, by generalizing the approach of Agarwal et al. for the non-constrained version of the problem. The computational time of our algorithm scales <it> logarithmically </it> in the size of the policy space. This answers the main open question of Badanidiyuru et al.
We also extend our results to a variant where there are no knapsack constraints but the objective is an arbitrary Lipschitz concave function of the sum of outcome vectors.
						</p>
					</font></div></li>


    <li> <b>ProjecToR: Agile Reconfigurable Datacenter Interconnect</b>
			[<a href="pubs/projector-sigcomm-cr"> pdf</a> |  <a   href = "#CBwK" onclick="toggle_visibility('absPTOR');">Show/Hide  Abstract</a>]
			<br> with  M. Ghobadi, R. Mahajan, A. Phanishayee, H. Rastegarfar, P. Blanche, M. Glick, D. Kilper, J. Kulkarni  and G. Ranade.
				In Proc. <i>SIGCOMM  2016</i>
				<div id="absPTOR" style="display:none"><font face="Arial" size="3">
						<p>
						We explore a radically different approach for building data center interconnects--using free-space optics between racks, it enables all rack-pairs to communicate via direct links and can reconfigure such links within 12us. Our approach uses a digital micromirror device (DMD) and mirror assembly combination as a transmitter and a photodetector on top of the rack as a receiver. Transmitters and receivers in our interconnect can be dynamically linked in billions of ways. We develop topology construction and routing methods to exploit this flexibility, including a new flow scheduling algorithm that is a constant factor approximation to the offline optimal solution. We build a small prototype that points to the feasibility of our approach. Simulations and analysis show that, for realistic data center workloads, it can improve mean flow completion time by 30-95%, while reducing cost by 25-40%.
						</p>
					</font></div></li>



				<li> <b> Multi-Score Position Auctions</b>
			[<a href="pubs/DSA.pdf">pdf</a>| <a   href = "#DSA" onclick="toggle_visibility('absDSA');">Show/Hide  Abstract</a>]
			<br> with Denis X. Charles  and Balasubramanian Sivan.
				In Proc. <i>WSDM 2016. </i>
				<div id="absDSA" style="display:none"><font face="Arial" size="3">
						<p>
							In this paper we propose a general family of position auctions used in paid search, which we call multi-score position auctions. These auctions contain the GSP auction and the GSP auction with squashing as special cases. We show experimentally that these auctions contain special cases that perform  better than the GSP auction with squashing, in terms of revenue, and the number of clicks on ads. In particular, we study in detail the special case that squashes the first slot alone and show that this beats pure squashing (which squashes all slots uniformly). We study the equilibria that arise in this special case to examine both the first order and the second order effect of moving from the squashing-all-slots auction to the squash-only-the-top-slot auction. For studying the second order effect, we simulate auctions using the value-relevance correlated distribution suggested in Lahaie and Pennock [2007]. Since this distribution is derived from a study of value and relevance distributions in Yahoo! we believe the insights derived from this simulation to be valuable. For measuring the first order effect, in addition to the said simulation, we also conduct experiments using auction data from Bing over several weeks that includes a random sample of all auctions.

						</p>
					</font></div></li>



			<li> <b> Simple Pricing Schemes For Consumers With Evolving Values</b>
				[<a href="pubs/ppp.pdf">pdf</a>| <a   href = "#PPP" onclick="toggle_visibility('absPPP');">Show/Hide  Abstract</a>]
				<br> with Shuchi Chawla, Anna Karlin and Balasubramanian Sivan.
					In Proc. <i>SODA 2016. </i>
					<div id="absPPP" style="display:none"><font face="Arial" size="3">
							<p>
								We consider a pricing problem where a buyer is interested in purchasing/using a good, such as an app or music or software, repeatedly over time. The consumer discovers his value for the good only as he uses it, and the value evolves with each use. Optimizing for the seller's revenue in such dynamic settings is a complex problem and requires assumptions about how the buyer behaves before learning his future value(s), and in particular, how he reacts to risk. We explore the performance of a class of pricing mechanisms that are extremely simple for both the buyer and the seller to use: the buyer reacts to prices myopically without worrying about how his value evolves in the future; the seller needs to optimize for revenue over a space of only two parameters, and can do so without knowing the buyer's risk profile or fine details of the value evolution process. We present simple-versus-optimal type results, namely that under certain assumptions, simple pricing mechanisms of the above form are approximately optimal <i> regardless of the buyer's risk profile </i>.

								Our results assume that the buyer's value per usage evolves as a martingale. For our main result, we consider pricing mechanisms in which the seller offers the product for free for a certain number of uses, and then charges an appropriate fixed price per usage. We assume that the buyer responds by buying the product for as long as his value exceeds the fixed price. Importantly, the buyer does not need to know anything about how his future value will evolve, only how much he wants to use the product <i> right now </i>. Regardless of the buyers' initial value, our pricing captures as revenue a constant fraction of the total value that the buyers accumulate in expectation over time.
							</p>
						</font></div></li>


</ul>

<!-------------------------------------------------------------->
<b>2015</b> <ul>
<!-------------------------------------------------------------->

<li> <b> Speed Scaling in the Non-clairvoyant Model </b>
[<a href="pubs/spaa035-azarA.pdf">pdf</a>| <a   href = "#NCS" onclick="toggle_visibility('absNCS');">Show/Hide  Abstract</a>]
<br> with Yossi Azar, Zhiyi Huang and Debmalya Panigrahi.
In Proc. <i>SPAA 2015. </i> Winner of the <b> Best Paper award.</b>
<div id="absNCS" style="display:none"><font face="Arial" size="3">
<p>
In recent years, there has been a growing interest in speed scaling
algorithms, where a set of jobs need to be scheduled on a machine
with variable speed so as to optimize the flow-times of the jobs
and the energy consumed by the machine. A series of results have
culminated in constant-competitive algorithms for this problem in
the clairvoyant model, i.e., when job parameters are revealed on
releasing a job (Bansal, Pruhs, and Stein, SODA 2007; Bansal, Chan,
and Pruhs, SODA 2009). Our main contribution in this paper is
the first constant-competitive speed scaling algorithm in the non-
clairvoyant model, which is typically used in the scheduling literature
to model practical settings where job volume is revealed only
after the job has been completely processed. Unlike in the clairvoyant model,
the speed scaling problem in the non-clairvoyant model
is non-trivial even for a single job. Our non-clairvoyant algorithm
is defined by using the existing clairvoyant algorithm in a novel
inductive way, which then leads to an inductive analytical tool that
may be of independent interest for other online optimization
problems. We also give additional algorithmic results and lower bounds
for speed scaling on multiple identical parallel machines.
</p>
 </font></div></li>

<li> <b>Simple Auctions with Simple Strategies </b>
[<a href="pubs/Draft-OneShot.pdf">pdf</a>| <a   href = "#CP" onclick="toggle_visibility('absDA');">Show/Hide  Abstract</a>]
<br> with Jamie Morgenstern, Vasilis Syrgkanis and Matt Weinberg.
In Proc. <i>EC 2015</i>
<div id="absDA" style="display:none"><font face="Arial" size="3">
<p>
We introduce single-bid auctions as a new format for
combinatorial auctions. In single-bid auctions, each bidder submits a
single real-valued bid for the right to buy items at a fixed
price. Contrary to other simple auction formats, such as simultaneous
or sequential single-item auctions, bidders can implement no-regret
learning strategies for single-bid auctions in polynomial time. Price of
anarchy bounds for correlated equilibria concepts in single-bid auctions
therefore have more bite than their counterparts for auctions and
equilibria for which learning is not known to be computationally
tractable (or worse, known to be computationally
<it>in</it>tractable). Towards this end,
we show that for any subadditive valuations the social welfare at
equilibrium is an O(log m)  approximation to the optimal social
welfare, where  m  is the number of items. We also provide tighter
approximation results for several subclasses. Our welfare guarantees
hold for Nash equilibria and no-regret learning outcomes in both
Bayesian and complete information settings via the smooth-mechanism
framework. Of independent interest, our techniques show that in a
combinatorial auction setting, efficiency guarantees of a mechanism
via smoothness for a very restricted class ofcardinality it
valuations extend, with a small degradation, to subadditive
valuations, the largest complement-free class of valuations.
</p>
 </font></div></li>


<li> <b>Revenue Maximization and Ex-Post Budget Constraints </b>
[<a href="pubs/Revenue Max Budget Constraints.pdf">pdf</a>| <a   href = "#RMBC" onclick="toggle_visibility('absRMBC');">Show/Hide  Abstract</a>]
<br> with Constantinos Daskalakis and Matt Weinberg.
In Proc. <i>EC 2015</i>
<div id="absRMBC" style="display:none"><font face="Arial" size="3">
<p>
We consider the problem of a revenue-maximizing seller with m items for sale to n additive bidders with hard
budget constraints, assuming that the seller has some prior distribution over bidder values and budgets. The prior
may be correlated across items and budgets of the same bidder, but is assumed independent across bidders. We
target mechanisms that are Bayesian Incentive Compatible, but that are ex-post Individually Rational and ex-post
budget respecting. Virtually no such mechanisms are known that satisfy all these conditions and guarantee any
revenue approximation, even with just a single item. We provide a computationally efﬁcient mechanism that is
a 3-approximation with respect to all BIC, ex-post IR, and ex-post budget respecting mechanisms. Note that the
problem is NP-hard to approximate better than a factor of 16/15, even in the case where the prior is a point
mass [Chakrabarty and Goel 2010]. We further characterize the optimal mechanism in this setting, showing that
it can be interpreted as a distribution over virtual welfare maximizers.
We prove our results by making use of a black-box reduction from mechanism to algorithm design developed
by [Cai et al. 2013]. Our main technical contribution is a computationally efﬁcient 3-approximation algorithm for
the algorithmic problem that results by an application of their framework to this problem. The algorithmic problem
has a mixed-sign objective and is NP-hard to optimize exactly, so it is surprising that a computationally efﬁcient
approximation is possible at all. In the case of a single item (m = 1), the algorithmic problem can be solved exactly
via exhaustive search, leading to a computationally efﬁcient exact algorithm and a stronger characterization of
the optimal mechanism as a distribution over virtual value maximizers.
 </p>
 </font></div></li>

<li> <b>Fast Algorithms for Online Stochastic Convex Programming
</b>[<a href="pubs/ConvexSecretary.pdf">pdf</a>|<a   href = "#FAOSCP" onclick="toggle_visibility('absFAOSCP');">Show/Hide  Abstract</a>]<br>
with Shipra Agrawal.
In Proc. <i>SODA 2015</i>
 <div id="absFAOSCP" style="display:none"><font face="Arial" size="3">
<p>
We introduce the online stochastic Convex Programming (CP) problem, a very general version of stochas-
tic online problems which allows arbitrary concave objectives and convex feasibility constraints. Many well-
studied problems like online stochastic packing and covering, online stochastic matching with concave returns,
etc. form a special case of online stochastic CP. We present fast algorithms for these problems, which achieve
near-optimal regret guarantees for both the i.i.d. and the random permutation models of stochastic inputs.
When applied to the special case online packing, our ideas yield a simpler and faster primal-dual algorithm
for this well studied problem, which achieves the optimal competitive ratio. Our techniques make explicit the
connection of primal-dual paradigm and online learning to online stochastic CP.
 </p>
 </font></div>
 </li>

<li> <b>Perfect Bayesian Equilibria in Repeated Sales
</b>
[<a href="http://arxiv.org/abs/1409.3062.pdf">Arxiv pdf </a>| <a   href = "#PBE" onclick="toggle_visibility('absPBE');">Show/Hide  Abstract</a>]
<br>with  Yuval Peres and Balasubramanian Sivan.
In Proc. <i>SODA 2015</i>
 <div id="absPBE" style="display:none"><font face="Arial" size="3">
<p>
  A special case of Myerson's classic result describes the revenue-optimal
equilibrium when a seller offers a single item to a buyer. We study a repeated
sales extension of this model: a seller offers to sell a single fresh copy of
an item to the same buyer every day via a posted price. The buyer's value for
the item is unknown to the seller but is drawn initially from a publicly known
distribution F and remains the same throughout.
  We study this setting where the seller is unable to commit to future prices
and find several surprises. First, if the horizon is fixed, previous work
showed that an equilibrium exists, and all equilibria yield tiny or constant
revenue. This is a far cry from the linearly growing benchmark of getting
Myerson optimal revenue each day. Our first result shows that this is because
the buyer strategies in these equilibria are necessarily unnatural. We restrict
to a natural class of buyer strategies called threshold strategies, and show
that threshold equilibria rarely exist. Second, if the seller can commit not to
raise prices upon purchase, while still retaining the possibility of lowering
prices in future, we show that threshold equilibria always exist and for most
distributions there is a unique threshold equilibrium. As an example, if F is
uniform in [0,1], the seller can extract revenue of order $\sqrt{n}$ in $n$
rounds as opposed to the constant revenue obtainable when he is unable to make
commitments. Finally, we consider the infinite horizon game, where both the
seller and the buyer discount the future utility by a factor of $1-\delta \in
[0,1)$. When the value distribution is uniform in [0,1], there exists a
threshold equilibrium with expected revenue at least $\frac{4}{3+2\sqrt{2}}
\sim 69$\% of the Myerson optimal revenue benchmark. This is in sharp contrast
to the constant revenue obtained in the limit of the $n$-stage games as $n$
approaches infinity.

 </p>
 </font></div>
 </li>





<li> <b> Budget Constraints in Prediction Markets </b>
[<a href="pubs/ddhpuai15.pdf">pdf</a>| <a   href = "#BCPM" onclick="toggle_visibility('absBCPM');">Show/Hide  Abstract</a>]
<br> with Miro Dudik, Zhiyi Huang and Dave Pennock.
In Proc. <i>UAI 2015</i>
<div id="absBCPM" style="display:none"><font face="Arial" size="3">
<p>
An automated market maker is a natural and
common mechanism to subsidize information
acquisition, revelation, and aggregation in a
prediction market. The sought-after prediction
aggregate is the equilibrium price. However, traders
with budget constraints are restricted in their
ability to impact the market price on their own.
We give a detailed characterization of optimal
trades in the presence of budget constraints in a
prediction market with a cost-function-based
automated market maker. As a concrete application
of our characterization, we give sufficient
conditions for a property we call budget additivity:
two traders with budgets B and B'
and the same beliefs would have a combined impact equal to a
single trader with budget B +B'. That way, even
if a single trader cannot move the market much, a
crowd of like-minded traders can have the same
desired effect. We show that a generalization of
the heavily-used logarithmic market scoring rule
is budget additive for affinely independent
payoffs, but the quadratic market scoring rule is not.
Our results may be used both descriptively, to
understand if a particular market maker is affected
by budget constraints or not, and prescriptively,
as a recipe to construct markets.
</p>
 </font></div></li>


</ul>
<!-------------------------------------------------------------->
<b>2014</b> <ul>
<!-------------------------------------------------------------->
<li> <b>Envy freedom and prior-free mechanism design
</b> [<a href="http://www.sciencedirect.com/science/article/pii/S0022053114001094">JET </a>| <a href="http://arxiv.org/pdf/1212.3741.pdf">Arxiv pdf </a>|
<a   href = "#EFPF" onclick="toggle_visibility('absEFPF');">Show/Hide  Abstract</a>]<br>
with Jason D. Hartline and Qiqi Yan.
In <i>Journal of Economic Theory, 2014</i>
 <div id="absEFPF" style="display:none"><font face="Arial" size="3">
<p>
We consider the provision of an abstract service to single-dimensional agents. Our model includes position auctions, single-minded combinatorial auctions, and constrained matching markets. When the agents' values are drawn independently from a distribution, the Bayesian optimal mechanism is given by Myerson as a virtual-surplus optimizer. We develop a framework for prior-free mechanism design and analysis. A good mechanism in our framework approximates the optimal mechanism for the distribution if there is a distribution; moreover, when there is no distribution this mechanism still provably performs well.
<BR>
We define and characterize optimal envy-free outcomes in symmetric single-dimensional environments. Our characterization mirrors Myerson's theory. Furthermore, unlike in mechanism design where there is no point-wise optimal mechanism, there is always a point-wise optimal envy-free outcome.
<br>
Envy-free outcomes and incentive-compatible mechanisms are similar in structure and performance. We therefore use the optimal envy-free revenue as a benchmark for measuring the performance of a prior-free mechanism. A good mechanism is one that approximates the envy-free benchmark on any profile of agent values. We show that good mechanisms exist, and in particular, a natural generalization of the random sampling auction of Goldberg et al. is a constant approximation.

 </p>
 </font></div>
 </li>

<li> <b>Bandits with concave rewards and convex knapsacks
</b> [<a href="http://arxiv.org/pdf/1402.5758v1.pdf">Arxiv pdf </a>| <a   href = "#BwCR" onclick="toggle_visibility('absBwCR');">Show/Hide  Abstract</a>]<br>
with Shipra Agrawal.
In Proc. <i>ACM EC 2014</i>
 <div id="absBwCR" style="display:none"><font face="Arial" size="3">
<p>
In this paper, we consider a very general model for exploration-exploitation tradeoff which allows arbitrary concave rewards and convex constraints on the decisions across time, in addition to the customary limitation on the time horizon. This model subsumes the classic multi-armed bandit (MAB) model, and the Bandits with Knapsacks (BwK) model of Badanidiyuru et al.[2013]. We also consider an extension of this model to allow linear contexts, similar to the linear contextual extension of the MAB model. We demonstrate that a natural and simple extension of the UCB family of algorithms for MAB provides a polynomial time algorithm that has near-optimal regret guarantees for this substantially more general model, and matches the bounds provided by Badanidiyuru et al.[2013] for the special case of BwK, which is quite surprising. We also provide computationally more efficient algorithms by establishing interesting connections between this problem and other well studied problems/algorithms such as the Blackwell approachability problem, online convex optimization, and the Frank-Wolfe technique for convex optimization. We give examples of several concrete applications, where this more general model of bandits allows for richer and/or more efficient formulations of the problem.
 </p>
 </font></div>
 </li>


<li> <b>Removing Arbitrage from Wagering Mechanisms </b>
[<a href="pubs/Wagering-full.pdf">pdf </a>| <a   href = "#NAWM" onclick="toggle_visibility('absNAWM');">Show/Hide  Abstract</a>]
<br>with Yiling Chen, David Pennock, Jennifer Wortman Vaughan.
In Proc. <i>ACM EC 2014</i>
 <div id="absNAWM" style="display:none"><font face="Arial" size="3">
<p>
We observe that Lambert et al.'s [2008] family of weighted score wagering mechanisms admit arbitrage:
participants can extract a guaranteed positive payoﬀ by betting on any prediction within a certain range.
In essence, participants leave free money on the table when they "agree to disagree", and as a result,
rewards don’t necessarily go to the most informed and accurate participants. This observation suggests
that when participants have immutable beliefs, it may be possible to design alternative mechanisms in
which the center can make a proﬁt by removing this arbitrage opportunity without sacriﬁcing incentive
properties such as individual rationality, incentive compatibility, and sybilproofness. We introduce a new
family of wagering mechanisms called no-arbitrage wagering mechanisms that retain many of the positive
properties of weighted score wagering mechanisms, but with the arbitrage opportunity removed. We show
several structural results about the class of mechanisms that satisfy no-arbitrage in conjunction with other
properties, and provide examples of no-arbitrage wagering mechanisms with interesting properties.
 </p>
 </font></div>
 </li>


<li> <b>Primal dual gives optimal energy efficient online algorithms
</b> [<a href="pubs/DH14-SODA.pdf">pdf </a>| <a   href = "#DH14" onclick="toggle_visibility('absDH-14');">Show/Hide  Abstract</a>]<br>
with Zhiyi Huang.
In Proc. <i>SODA 2014</i>
 <div id="absDH-14" style="display:none"><font face="Arial" size="3">
<p>
We consider the problem of online scheduling of jobs on unrelated machines with dynamic speed scaling to minimize the sum of energy and weighted flow time. We give an algorithm with an almost optimal competitive ratio for arbitrary power functions. (No earlier results handled arbitrary power functions for unrelated machines.) For power functions of the form $f(s) = s^\alpha$ for some constant $\alpha>1$, we get a competitive ratio of $O(\tfrac {\alpha} {\log \alpha}) $, improving upon a previous competitive ratio of $O(\alpha^2)$ by Anand et al., along with a matching lower bound of  $\Omega(\tfrac {\alpha} {\log \alpha})$. Further, in the resource augmentation model, with a 1+ $\epsilon$ speed up, we give a $2( \tfrac 1 \epsilon+1)$ competitive algorithm, with essentially the same techniques, improving the bound of $1 + O(\frac{1}{\epsilon^2})$ by Gupta et al. and matching the bound of  Anand et al. for the special case of fixed speed unrelated machines.   Unlike the previous results most of which used an amortized local competitiveness argument or dual fitting methods, we use a primal-dual method, which is useful not only to analyze the algorithms but also to design the algorithm itself.
 </p>
 </font></div>
 </li>

</ul>
<!-------------------------------------------------------------->
<b>2013</b> <ul>
<!-------------------------------------------------------------->

<li> <b>
Whole-page Optimization and Submodular Welfare Maximization with Online Bidders</b> [<a href="pubs/ec-free-disposal.pdf">pdf </a>| <a   href = "#CP" onclick="toggle_visibility('absFD');">Show/Hide  Abstract</a>]<br>
with Zhiyi Huang, Nitish Korula, Vahab Mirrokni and Qiqi Yan.
In Proc. <i>ACM EC 2013</i>
 <div id="absFD" style="display:none"><font face="Arial" size="3">
<p>
In the context of online ad serving, display ads may appear on different types of web-pages, where each
page includes several ad slots and therefore multiple ads can be shown on each page. The set of ads that
can be assigned to ad slots of the same page needs to satisfy various pre-specified constraints including
exclusion  constraints,  diversity  constraints,  and  the  like.  Upon  arrival  of  a  user,  the  ad  serving  system
needs to allocate a set of ads to the current web-page respecting these per-page allocation constraints.
Previous slot-based settings ignore the important concept of a page, and may lead to highly suboptimal
results in general. In this paper, motivated by these applications in display advertising and inspired by the
submodular welfare maximization problem with online bidders, we study a general class of page-based ad
allocation problems, present the first (tight) constant-factor approximation algorithms for these problems,
and confirm the performance of our algorithms experimentally on real-world data sets.
A key technical ingredient of our results is a novel primal-dual analysis for handling free-disposal, which
updates dual variables using a "level function" instead of a single level, and unifies with previous analyses
of related problems. This new analysis method allows us to handle arbitrarily complicated allocation
constraints for each page. Our main result is an algorithm that achieves a 1 - 1/e - o(1) competitive
ratio. Moreover, our experiments on real-world data sets show signi?cant improvements of our page-based
algorithms compared to the slot-based algorithms.
Finally, we observe that our problem is closely related to the submodular welfare maximization (SWM)
problem. In particular, we introduce a variant of the SWM problem with online bidders, and show how to
solve this problem using our algorithm for whole page optimization.
 </p>
 </font></div>
 </li>

<li> <b>
Budget Smoothing for Internet Ad Auctions: A Game Theoretic
Approach</b> [<a href="pubs/ec44-charles.pdf">pdf </a>| <a   href = "#CP" onclick="toggle_visibility('absBS');">Show/Hide  Abstract</a>]<br>
with Deeparnab Chakrabarty, Denis Charles, Max Chickering and Lei Wang.
In Proc. <i>ACM EC 2013</i>
 <div id="absBS" style="display:none"><font face="Arial" size="3">
<p>
In Internet ad auctions, search engines often throttle budget constrained advertisers so as to spread their
spends across the specified time period. Such policies are known as budget smoothing policies. In this paper,
we perform a principled, game-theoretic study of what the outcome of an ideal budget smoothing algorithm
should be. In particular, we propose the notion of regret-free budget smoothing policies whose outcomes
throttle each advertiser optimally, given the participation of the other advertisers. We show that regret-free
budget smoothing policies always exist, and in the case of single slot auctions we can give a polynomial time
smoothing algorithm. Inspired by the existence proof, we design a heuristic for budget smoothing which
performs considerably better than existing benchmark heuristics.
 </p>
 </font></div>
 </li>

 <li> <b>
Prior-free Auctions for Budgeted Agents
</b>[<a href="pubs/ec14-devanur.pdf">pdf </a>| <a   href = "#CP" onclick="toggle_visibility('absPFABA');">Show/Hide  Abstract</a>]<br>
with Bach Q. Ha and Jason D. Hartline.
In Proc. <i>ACM EC 2013</i>
 <div id="absPFABA" style="display:none"><font face="Arial" size="3">
<p>
We consider prior-free auctions for revenue and welfare maximization when agents have a common budget.
The abstract environments we consider are ones where there is a downward-closed and symmetric feasibility
constraint on the probabilities of service of the agents. These environments include position auctions where
slots with decreasing click-through rates are auctioned to advertisers. We generalize and characterize the
envy-free benchmark from Hartline and Yan [2011] to settings with budgets and characterize the optimal
envy-free outcomes for both welfare and revenue. We give prior-free mechanisms that approximate these
benchmarks. A building block in our mechanism is a clinching auction for position auction environments.
This auction is a generalization of the multi-unit clinching auction of Dobzinski et al. [2008] and a special
case of the polyhedral clinching auction of Goel et al. [2012]. For welfare maximization, we show that this
clinching auction is a good approximation to the envy-free optimal welfare for position auction environments.
For profit maximization, we generalize the random sampling profit extraction auction from Fiat et al. [2002]
for digital goods to give a 10.0-approximation to the envy-free optimal revenue in symmetric, downward-
closed environments. Even without budgets this revenue maximization question is of interest and we obtain
an improved approximation bound of 7.5 (from 30.4 by Ha and Hartline [2012]).
 </p>
 </font></div>
 </li>


 <li> <b>
Tatonnement Beyond Gross Substitutes? Gradient Descent to the Rescue </b>[<a href="pubs/tatonnement-gradient-descent.pdf">pdf </a>| <a   href = "#CP" onclick="toggle_visibility('absTAT');">Show/Hide  Abstract</a>]<br>
with Yun Kuen Cheung and Richard Cole.
In Proc. <i> STOC 2013</i>. To appear in <i> GEB </i>.
 <div id="absTAT" style="display:none"><font face="Arial" size="3">
<p>
Tatonnement is a simple and natural rule for updating prices
in Exchange (Arrow-Debreu) markets. In this paper we de-
?ne a class of markets for which tatonnement is equivalent
to gradient descent.  This is the class of markets for which
there is a convex potential function whose gradient is always
equal to the negative of the excess demand and we call it
Convex Potential Function (CPF) markets.   We show the
following results.
<ul>
<li>CPF markets contain the class of Eisenberg Gale (EG)
markets, de?ned previously by Jain and Vazirani.</li>
<li> The subclass of CPF markets for which the demand
is a differentiable function contains exactly those mar-
kets whose demand function has a symmetric negative
semi-definite Jacobian.</li>
<li> We  de?ne  a  family  of  continuous  versions  of  taton-
nement  based  on  gradient  descent  using  a  Bregman
divergence.  As we show, all processes in this family
converge to an equilibrium for any CPF market. This
is analogous to the classic result for markets satisfying
the Weak Gross Substitutes property.</li>
<li> A  discrete  version  of  tatonnement  converges  toward
the equilibrium for the following markets of comple-
mentary goods; its convergence rate for these settings
is analyzed using a common potential function.
<ul><li> Fisher markets in which all buyers have Leontief
utilities.   The  tatonnement  process  reduces  the
distance to the equilibrium, as measured by the
potential function, to an epsilon fraction of its initial
value in O(1/epsilon) rounds of price updates.</li>
<li> Fisher markets in which all buyers have comple-
mentary CES utilities.  Here, the distance to thequilibrium is reduced to epsilon fraction of its initial
value in O(log(1/epsilon)) rounds of price updates.</li>
</ul>
This shows that tatonnement converges for the entire
range of Fisher markets when buyers have complementary  CES  utilities,  in  contrast  to  prior  work,  which
could analyze only the substitutes range, together with
a small portion of the complementary range.
</ul>
 </p>
 </font></div>
 </li>


 <li> <b>
Randomized Primal-Dual Analysis of RANKING for Online Bipartite Matching
</b>[<a href="pubs/RPDFinal.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absKVV');">Show/Hide  Abstract</a>]<br>
with Kamal Jain and Bobby Kleinberg.
In Proc. <i>
 SODA  2013</i>
<div id="absKVV" style="display:none"><font face="Arial" size="3">
<p>
We give a simple proof that the RANKING algorithm of Karp, Vazirani and Vazirani  is 1-1/e competitive for the online bipartite matching problem. The proof is via a randomized primal-dual argument. Primal-dual algorithms have been successfully used for many online algorithm problems, but the dual constraints are always satisfied deterministically. This is the first instance of a non-trivial randomized primal-dual algorithm in which the dual constraints only hold in expectation. The approach also generalizes easily to the vertex-weighted version considered by Agarwal et al.  Further we show that the proof is very similar to the deterministic primal-dual argument for the online budgeted allocation problem with small bids (also called the AdWords problem) of Mehta et al.
  </p></font>
</div></li>
<!-------------------------------------------------------------->
</ul><b>2012</b> <ul>
<!-------------------------------------------------------------->
<li> <b>
Asymptotically Optimal Algorithm for Stochastic Adwords
</b>[<a href="pubs/AOASA.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absAOA');">Show/Hide  Abstract</a>]<br>
with Balasubramanian Sivan and Yossi Azar.
In Proc. <i>
 EC  2012</i>
<div id="absAOA" style="display:none"><font face="Arial" size="3">
<p>
In this paper we consider the adwords problem in the <i> unknown distribution </i>
model.  We consider the case where the budget to bid ratio $k$ is at least 2,
and give improved competitive ratios.  Earlier results had competitive ratios
better than $1-1/e$ only for ``large enough'' $k$, while our competitive ratio
increases continuously with $k$. For $k=2$ the competitive ratio we get is
$0.729$ and it is $0.9$ for $k=16$.  We also improve the asymptotic competitive
ratio for large $k$ from $1 - O(\sqrt{\log n /k})$ to $1 - O(\sqrt{1 /k})$, thus
removing any dependence on $n$, the number of advertisers. This ratio is
optimal, even with known distributions.  That is, even if an algorithm is
tailored to the distribution, it cannot get a competitive ratio of $1 -
o(\sqrt{1 /k})$, whereas our algorithm does not depend on the distribution.  The
algorithm is rather simple, it computes a <i> score </i> for every advertiser based
on his original budget, the remaining budget and the remaining number of steps
in the algorithm and assigns a query to the advertiser with the highest bid plus
his score. The analysis is based on a ``hybrid argument'' that considers
algorithms that are part actual, part hypothetical, to prove that our (actual)
algorithm is better than a completely hypothetical algorithm whose performance
is easy to analyze.
  </p></font>
</div></li>
<!-------------------------------------------------------------->
<!-------------------------------------------------------------->
<li> <b>
Online Matching with Concave Returns
  </b>[<a href="pubs/OMwCR.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absCM');">Show/Hide  Abstract</a>]<br>
with Kamal Jain.
In Proc. <i>
 STOC 2012</i>
<div id="absCM" style="display:none"><font face="Arial" size="3">
<p>
We consider a <i> significant </i>generalization of the Adwords problem by  <i> allowing arbitrary concave returns,
and we characterize the optimal competitive ratio achievable</i>.
The problem considers a sequence of items arriving online that have to be allocated to agents, with different agents bidding different amounts.
The objective function is the sum, over each agent i, of a monotonically non-decreasing concave function $M_i : R_+ \rightarrow R_+$ of the total amount allocated to i.
All variants of online matching problems (including the Adwords problem) studied in the literature consider the special case of budgeted linear functions,
that is,  functions of the form $M_i( u_i) = \min \{u_i,B_i\}$ for some constant $B_i$.
The distinguishing feature of this paper is in allowing arbitrary concave returns.
The main result of this paper is that for each concave function $M$, there exists a constant $F(M) \leq 1$ such that
<ul>
<li> there exists an algorithm with competitive ratio of \\$\min_i\{ F(M_i) \}$, independent of the sequence of items.
<LI> No algorithm has  a competitive ratio larger than $F(M)$ over all instances with $M_i= M$ for all $i$.
</ul>
Our algorithm is based on the primal-dual paradigm and makes use of convex programming duality.
The upper bounds are obtained by formulating the task of finding the right counterexample as an optimization problem.
This path takes us through the calculus of variations which deals with optimizing over continuous functions.
The algorithm and the upper bound are related to each other via a set of differential equations, which
points to a certain kind of duality between them.
  </p></font>
</div></li>
<!-------------------------------------------------------------->
</ul><b>2011</b> <ul>
<!-------------------------------------------------------------->
<li> <b>
		Real-Time Bidding Algorithms for Performance-Based  Display Ad Allocation
	</b>[<a href="pubs/rtb-perf.pdf">pdf</a>| <a   href = "#PR" onclick="toggle_visibility('absRTB');">Show/Hide  Abstract</a>]<br>
		with Ye Chen, Pavel Berkhin and Bo Anderson .
		In Proc. <i>
			KDD 2011 </i>
		<div id="absRTB" style="display:none"><font face="Arial" size="3">
				<p>
					We describe a real-time bidding algorithm for performance-based display ad allocation. A central issue in performance display advertising is matching campaigns to ad impressions, which can be formulated as a constrained optimization problem that maximizes revenue subject to constraints such as budget limits and inventory availability. The current practice is to solve the optimization problem offline at a tractable level of impression granularity (e.g., the placement level), and to serve ads online based on the precomputed static delivery scheme. Although this offline approach takes a global view to achieve optimality, it fails to scale to ad delivery decision making at an individual impression level. Therefore, we propose a real-time bidding algorithm that enables fine-grained impression valuation (e.g., targeting users with real-time conversion data), and adjusts value-based bid according to real-time constraint snapshot (e.g., budget consumption level). Theoretically, we show that under a linear programming (LP) primal-dual formulation, the simple real-time bidding algorithm is indeed an online solver to the original primal problem by taking the optimal solution to the dual problem as input. In other words, the online algorithm guarantees the offline optimality given the same level of knowledge an offline optimization would have. Empirically, we develop and experiment with two real-time bid adjustment approaches to adapting to the non-stationary nature of the marketplace: one adjusts bids against real-time constraint satisfaction level using control-theoretic methods, and the other adjusts bids also based on the historical bidding landscape statistically modeled. Finally, we show experimental results with real-world ad serving data.
				</p></font>
		</div></li>
	<!-------------------------------------------------------------->
 <!-------------------------------------------------------------->
<li> <b>
Online Algorithms with Stochastic Input
  </b>[<a href="pubs/AdwordsStochastic.pdf">pdf </a>]<br>
In  <i>
ACM SIGEcom Exchanges, Vol. 10, No. 2, June 2011, Pages 40- 49. </i>
</li>
<!-------------------------------------------------------------->


<!-------------------------------------------------------------->
<li> <b>
Near Optimal Online Algorithms and Fast Approximation
Algorithms for Resource Allocation Problems
  </b>[<a href="pubs/GWLfull.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absGWL');">Show/Hide  Abstract</a>]<br>
with Kamal Jain, Balasubramanian Sivan and Christopher A. Wilkens
In Proc. <i>
 ACM EC 2011 </i>
<div id="absGWL" style="display:none"><font face="Arial" size="3">
<p>
We present algorithms for a class of resource allocation problems both in the online setting with stochastic input
and in the ofﬂine setting. This class of problems contains many interesting special cases such as the Adwords problem.
In the online setting we introduce a new distributional model called the adversarial stochastic input model, which is
a generalization of the i.i.d model with unknown distributions, where the distributions can change over time.  In this
model we give a 1 - O(epsilon) approximation algorithm for the resource allocation problem, with almost the weakest
possible assumption: the ratio of the maximum amount of resource consumed by any single request to the total capacity
of the resource, and the ratio of the proﬁt contributed by any single request to the optimal proﬁt is at most O (epsilon^2 /log(n/epsilon)  where n is the number of resources available. There are instances where this ratio is epsilon^2/log n such that no randomized
algorithm can have a competitive ratio of 1 - o(epsilon^2) even in the i.i.d model.  The upper bound on ratio that we require
improves on the previous upper-bound for the i.i.d case by a factor of n.
Our proof technique also gives a very simple proof that the greedy algorithm has a competitive ratio of 1 - 1/e for
the Adwords problem in the i.i.d model with unknown distributions, and more generally in the adversarial stochastic
input model, when there is no bound on the bid to budget ratio. All the previous proofs assume that either bids are very
small compared to budgets or something very similar to this.
In the ofﬂine setting we give a fast algorithm to solve very large LPs with both packing and covering constraints.
We give algorithms to approximately solve (within a factor of 1 + epsilon) the mixed packing-covering problem with
O(gamma m log(n/delta)/epsilon^2 ) oracle calls where the constraint matrix of this LP has dimension n x m,  the success probability
of the algorithm is 1 - delta, and gamma is a parameter which is very similar to the ratio described for the online setting.
We discuss several applications, and how our algorithms improve existing results in some of these applications.

  </p></font>
</div></li>
<!-------------------------------------------------------------->
<!-------------------------------------------------------------->
<li> <b>
Distributed Algorithms via Gradient Descent
for Fisher Markets
  </b>[<a href="pubs/propresponse.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absPR');">Show/Hide  Abstract</a>]<br>
with Benjamin Birnbaum and Lin Xiao.
In Proc. <i>
ACM  EC 2011</i>
<div id="absPR" style="display:none"><font face="Arial" size="3">
<p>
Designing distributed algorithms that converge quickly to an equi-
librium is one of the foremost research goals in algorithmic game
theory, and convex programs have played a crucial role in the de-
sign of algorithms for Fisher markets.  In this paper we shed new
light on both aspects for Fisher markets with linear and spending
constraint utilities. We show fast convergence of the Proportional
Response dynamics recently introduced by Wu and Zhang [WZ07].
The convergence is obtained from a new perspective: we show that
the Proportional Response dynamics is equivalent to a gradient de-
scent algorithm (with respect to a Bregman divergence instead of
euclidean distance) on a convex program that captures the equilib-
ria for linear utilities.  We further show that the convex program
program easily extends to the case of spending constraint utilities,
thus resolving an open question raised by [Vaz10]. This also gives
a way to extend the Proportional Response dynamics to spending
constraint utilties. We also prove a technical result that is interest-
ing in its own right: that the gradient descent algorithm based on a
Bregman divergence converges with rate O(1/t) under a condition
that is weaker than having Lipschitz continuous gradient (which is
the usual assumption in the optimization literature for obtaining the
same rate).

  </p></font>
</div></li>
<!-------------------------------------------------------------->
</ul><b>2010</b> <ul>
<!-------------------------------------------------------------->

<li> <b>
Fast Algorithms for Finding Matchings in Lopsided
Bipartite Graphs with Applications to Display Ads
  </b>[<a href="pubs/waterlevel.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absWL');">Show/Hide  Abstract</a>]<br>
with Denis Charles, Max Chickering, Kamal Jain and Manan Sanghi.
In Proc. <i>
ACM EC 2010  </i>
<div id="absWL" style="display:none"><font face="Arial" size="3">
<p>
   We derive efficient algorithms for both detecting and representing
matchings in lopsided bipartite graphs; such graphs have so many
nodes on one side that it is infeasible to represent them in memory or
to identify matchings using standard approaches. Detecting and
representing matchings in lopsided bipartite graphs is important for
allocating and delivering guaranteed-placement display
ads, where the corresponding bipartite graph of interest has nodes
representing advertisers on one side and nodes representing web-page
impressions on the other; real-world instances of such graphs can have
billions of impression nodes. We provide theoretical guarantees for
our algorithms, and in a real-world advertising application, we
demonstrate the feasibility of our detection algorithms.

  </p></font>
</div></li>
<li> <b>
Monotonicity in Bargaining Networks
  </b>[<a href="pubs/monotonicity.pdf">pdf </a> | <a   href = "#MON" onclick="toggle_visibility('absMON');">Show/Hide  Abstract</a>]<br>
with  Yossi Azar, Kamal Jain and Yuval Rabani.
In Proc. <i>
SODA 2010
  </i>
<div id="absMON" style="display:none"><font face="Arial" size="3">
<p>
  We study bargaining networks, discussed in a recent paper of Kleinberg and
Tardos, from the perspective of cooperative game theory. In
particular we examine three solution concepts, the nucleolus, the core
center and the core median.
All  solution concepts define unique solutions, so they provide
testable predictions.
We define a new monotonicity property that is a natural axiom of any bargaining game solution,
and we prove that all three of them satisfy this monotonicity property.
This is actually in contrast to the conventional wisdom for general cooperative games that
monotonicity and the core condition (which is a basic property that all three of them satisfy)
are incompatible with each other.
Our proofs are based on a
primal-dual argument (for the nucleolus) and on the FKG inequality (for the
core center and the core median). We further observe some qualitative differences between the
solution concepts. In particular, there are cases where a strict version of
our monotonicity property is a natural axiom, but only the core center and the core median
satisfy it. On the other hand, the nucleolus is easy to compute, whereas
computing the core center or the core median is #P-hard (yet it can be approximated in
polynomial time).</p></font>
</div>

</li>
<!-------------------------------------------------------------->
</ul><b>2009</b> <ul>
<!-------------------------------------------------------------->

<li> <b>
Convergence of Local Dynamics to Balanced Outcomes in Exchange Networks
  </b>[<a href="pubs/edgebalancing.pdf">pdf </a> | <a   href = "#EB" onclick="toggle_visibility('absEB');">Show/Hide  Abstract</a>]<br>
with Yossi Azar, Benjamin Birnbaum, L. Elisa Celis  and Yuval Peres.
In Proc. <i>
FOCS 2009
  </i>
<div id="absEB" style="display:none"><font face="Arial" size="3">
<p>
  Bargaining games on exchange networks have been
studied by both economists and sociologists. A Balanced Out-
come for such a game is an equilibrium concept that
combines notions of stability and fairness. In a recent paper,
Kleinberg and Tardos introduced balanced outcomes to the
computer science community and provided a polynomial-time
algorithm to compute the set of such outcomes. Their work left
open a pertinent question: are there natural, local dynamics that
converge quickly to a balanced outcome? In this paper, we provide
a partial answer to this question by showing that simple edge-
balancing dynamics converge to a balanced outcome whenever one
exists.
</p>
  </font>
</div>


</li>
<li> <b>
The Price of Truthfulness for Pay-Per-Click Auctions
  </b>[<a href="pubs/ppc.pdf">pdf</a> | <a   href = "#PPC" onclick="toggle_visibility('absPPC');">Show/Hide  Abstract</a>]<br>
with Sham Kakade.
In Proc. <i>
ACM EC 2009.
  </i>
<div id="absPPC" style="display:none"><font face="Arial" size="3">
<P>
  We analyze the problem of designing a truthful pay-per-click auction where
the click-through-rates (CTR) of the bidders are unknown to the auction. Such an auction faces the classic explore/exploit dilemma: while gathering information about the click through rates of advertisers, the mechanism may loose revenue; however, this gleaned information may prove valuable in the future for a more profitable allocation. In this sense, such mechanisms are prime candidates to be designed using multi-armed bandit techniques. However, a naive application of multi-armed bandit algorithms would not take into account the strategic considerations of the players --- players might manipulate their bids (which determine the auction's revenue) in a way as to maximize their own utility. Hence,
we consider the natural restriction that the auction be truthful.

The revenue that we could hope to achieve is the expected revenue of a
Vickrey auction that knows the true CTRs, and we define the truthful regret to be the difference
between the expected revenue of the auction and this Vickrey revenue. This work sharply characterizes what regret is achievable, under a truthful restriction. We show that this truthful restriction imposes statistical limits on the achievable regret --- the achievable regret is $\tilde{\Theta}(T^{2/3})$, while for traditional bandit algorithms (without the truthful restriction) the achievable regret is $\tilde{\Theta}(T^{1/2})$ (where $T$ is the number of rounds). We term the extra $T^{1/6}$ factor, the `price of truthfulness'.
  </P>
  </font>
</div>

</li>
<li> <b>
The Adwords Problem: Online Keyword Matching
with Budgeted Bidders under Random Permutations
  </b>[<a href="pubs/Adwords.pdf">pdf</a> | <a   href = "#ADW" onclick="toggle_visibility('absADW');">Show/Hide  Abstract</a>]<br>
with Tom Hayes.
In Proc. <i>
ACM EC 2009.
  </i>
<div id="absADW" style="display:none"><font face="Arial" size="3">
<P>
  We consider the problem of a search engine trying to assign a sequence
of search keywords to a set of competing bidders, each with a daily
spending limit.  The goal is to maximize the revenue generated by these
keyword sales, bearing in mind that, as some bidders may eventually
exceed their budget, not all keywords should be sold to the highest bidder.
We assume that the sequence of keywords (or equivalently, of bids)
is revealed on-line.  Our concern will be the competitive ratio for this
problem versus the off-line optimum.

We extend the current literature on this problem by considering the setting
where the keywords arrive in a random order.  In this setting we are able to
achieve a competitive ratio of $1-\epsilon$ under some mild, but necessary,
assumptions.  In contrast, it is already known that when the keywords arrive
in an adversarial order, the best competitive ratio is bounded away from 1.
Our algorithm is motivated by PAC learning, and proceeds in two parts: a
training phase, and an exploitation phase.
  </p>
  </font>
</div>

</li>
<li> <b>
Limited and Online Supply and the Bayesian foundations of prior-free mechanism design
  </b>[<a href="pubs/los.pdf">pdf</a> | <a   href = "#LOS" onclick="toggle_visibility('absLOS');">Show/Hide  Abstract</a>]<br>
with Jason Hartline.
In Proc. <i>
ACM EC 2009.
  </i>
<div id="absLOS" style="display:none"><font face="Arial" size="3">
  <p>
We study auctions for selling a limited supply of a single commodity
in the case where the supply is known in advance and the case it is
unknown and must be instead allocated in an online fashion.  The
latter variant was proposed by Mahdian and Saberi as a model of an
important phenomena in auctions for selling Internet advertising:
advertising impressions must be allocated as they arrive and the total
quantity available is unknown in advance.  We describe the Bayesian
optimal mechanism for these variants and extend the random sampling
auction of Goldberg et al. to address the prior-free
case. </p>  </font>
</div>

</li>






</font></ul>


 <div align="left">
          <table height="30"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

<table width="100%" bgcolor="#dbeaf5" border="0" cellpadding="5" cellspacing="0">
<tbody><tr><td align="left">
<font face="Arial" size="+1"> <a name="pub"> Other  Publications </a> </font>
 </td>
</tr></tbody></table>

<ul>
<font face="Trebuchet MS" size="3">

<!--
  <li> <b>

  </b>[<a href="pubs/.pdf">pdf</a>]<br>
with .
In Proc. <i>

  </i>
</li>
-->
<!-------------------------------------------------------------->
	<li> <b>
		A Unified Rounding Algorithm For Unrelated Machines Scheduling Problems.  </b>
	<!--	[<a href="">arXiv pdf</a>| <a   href = "#URA" onclick="toggle_visibility('absURA');">Show/Hide  Abstract</a>]. -->
	<br> with 			Janardhan Kulkarni.
		In Proc. <i>SPAA 2018</i>.
		<div id="absURA" style="display:none"><font face="Arial" size="3">
				<p>

				</p>
			</font></div>
	</li>
<!-------------------------------------------------------------->
  <li> <b>
A Rational Convex Program for Linear Arrow-Debreu Markets
  </b>[<a href="http://arxiv.org/pdf/1307.8037.pdf">pdf</a>| <a   href = "#RCP" onclick="toggle_visibility('absRCP');">Show/Hide  Abstract</a>]<br>
with  Jugal Garg and Laszlo A. Vegh .
In  <i> TEAC, </i> Volume 5 Issue 1, November 2016.
<div id="absRCP" style="display:none"><font face="Arial" size="3">
<p>
We give a new, flow-type convex program describing equilibrium solutions to linear Arrow-Debreu markets. Whereas convex formulations were previously known [Nenakov, Primak 83; Jain 07; Cornet '89], our program exhibits several new features. It gives a simple necessary and sufficient condition and a concise proof of the existence and rationality of equilibria, settling an open question raised by Vazirani. As a consequence we also obtain a simple new proof of Mertens's result that the equilibrium prices form a convex polyhedral set.
  </p></font>
</div>
</li>
<!-------------------------------------------------------------->
 <li> <b>
On the Approximation of Submodular Functions
  </b>[<a href="http://arxiv.org/pdf/1307.8037.pdf">pdf</a>| <a   href = "#ASM" onclick="toggle_visibility('absASM');">Show/Hide  Abstract</a>]<br>
with Shaddin Dughmi, Roy Schwartz, Ankit Sharma and Mohit Singh.
<!--In Proc. <i>  </i> -->
<div id="absASM" style="display:none"><font face="Arial" size="3">
<p>
Submodular functions are a fundamental object of study in combinatorial
optimization, economics, machine learning, etc. and exhibit a rich
combinatorial structure. Many subclasses of submodular functions have also been
well studied and these subclasses widely vary in their complexity. Our
motivation is to understand the relative complexity of these classes of
functions. Towards this, we consider the question of how well can one class of
submodular functions be approximated by another (simpler) class of submodular
functions. Such approximations naturally allow algorithms designed for the
simpler class to be applied to the bigger class of functions. We prove both
upper and lower bounds on such approximations.
<br />Our main results are:
<br />1. General submodular functions can be approximated by cut functions of
directed graphs to a factor of $n^2/4$, which is tight.
<br />2. General symmetric submodular functions$^{1}$ can be approximated by cut
functions of undirected graphs to a factor of $n-1$, which is tight up to a
constant.
<br />3. Budgeted additive functions can be approximated by coverage functions to a
factor of $e/(e-1)$, which is tight.
<br />Here $n$ is the size of the ground set on which the submodular function is
defined.
<br />We also observe that prior works imply that monotone submodular functions can
be approximated by coverage functions with a factor between $O(\sqrt{n} \log
n)$ and $\Omega(n^{1/3} /\log^2 n) $.

  </p></font>
</div>
</li>

<!-------------------------------------------------------------->
 <li> <b>
Sequential Auctions of Identical Items with Budget-Constrained Bidders
  </b>[<a href="http://arxiv.org/pdf/1209.1698.pdf">pdf</a>| <a   href = "#SAB" onclick="toggle_visibility('absSAB');">Show/Hide  Abstract</a>]<br>
with Zhiyi Huang and David Malec.
<!--In Proc. <i>  </i> -->
<div id="absSAB" style="display:none"><font face="Arial" size="3">
<p>
In this paper, we study sequential auctions with two budget constrained bidders and any number of identical items. All prior results on such auctions consider only two items. We construct a canonical outcome of the auction that is the only natural equilibrium and is unique under a refinement of subgame perfect equilibria. We show certain interesting properties of this equilibrium; for instance, we show that the prices decrease as the auction progresses. This phenomenon has been observed in many experiments and previous theoretic work attributed it to features such as uncertainty in the supply or risk averse bidders. We show that such features are not needed for this phenomenon and that it arises purely from the most essential features: budget constraints and the sequential nature of the auction. A little surprisingly we also show that in this equilibrium one agent wins all his items in the beginning and then the other agent wins the rest. The major difficulty in analyzing such sequential auctions has been in understanding how the selling prices of the first few rounds affect the utilities of the agents in the later rounds. We tackle this difficulty by identifying certain key properties of the auction and the proof is via a joint induction on all of them.
  </p></font>
</div>
</li>
<!-------------------------------------------------------------->
<li> <b>
Cloud Scheduling with Setup Cost
  </b>[<a href="pubs/schedule6.pdf">pdf</a>| <a   href = "#PR" onclick="toggle_visibility('absCSSC');">Show/Hide  Abstract</a>]<br>
with Yossi Azar, Naama Ben-Aroya and Navendu Jain.
In Proc. <i>
 SPAA 2013 </i>
<div id="absCSSC" style="display:none"><font face="Arial" size="3">
<p>
 In  this  paper,  we  investigate  the  problem  of  online  task
scheduling of jobs such as MapReduce jobs,  Monte Carlo
simulations  and  generating  search  index  from  web
documents, on cloud computing infrastructures. We consider the
virtualized cloud computing setup comprising machines that
host multiple identical virtual machines (VMs) under pay-as-you-go charging,
and that booting a VM requires a constant setup time.  The cost of job computation depends on
the number of VMs activated, and the VMs can be activated
and shutdown on demand.  We propose a new bi-objective
algorithm  to  minimize  the  maximum  task  delay,  and  the
total cost of the computation.  We study both the clairvoyant case,
where the duration of each task is known upon its
arrival, and the more realistic non-clairvoyant case.
  </p></font>
</div></li>
<!-------------------------------------------------------------->
<!-------------------------------------------------------------->
<li> <b>
Prior-Independent Multi-parameter Mechanism Design
  </b>[<a href="pubs/udca.pdf">pdf </a>| <a   href = "#PR" onclick="toggle_visibility('absPIMD');">Show/Hide  Abstract</a>]<br>
with  Jason D. Hartline, Anna R. Karlin, C. Thach Nguyen
In Proc. <i>
 WINE 2011 </i>
<div id="absPIMD" style="display:none"><font face="Arial" size="3">
<p>

In a multi-unit unit-demand multi-item auction, an auctioneer is selling a
collection of different items to a set of agents each interested
in buying at most unit. Each agent has a different
private value for each of the items. We consider the problem of designing a
truthful auction that maximizes the auctioneer's profit in this
setting. Previously, there has been progress on this problem
in the setting in which each value is drawn from a known prior
distribution. Specifically, it has been shown how to design auctions tailored
to these priors that achieve a constant factor approximation ratio profit.
In this paper, we present the first prior-independent auction for this
setting. This auction is guaranteed to achieve a constant fraction
of the optimal expected profit for a large class of, so called, ``regular'' distributions,
without specific knowledge of the distributions.
  </p></font>
</div></li>
<!--------------------------------------------------------------><!-------------------------------------------------------------->
<li> <b>
An O(n log n) Algorithm for a
Load Balancing Problem on Paths
  </b>[<a href="pubs/PathBalancing.pdf">pdf</a>| <a   href = "#PR" onclick="toggle_visibility('absPB');">Show/Hide  Abstract</a>]<br>
with Uri Feige.
 In Proc. <i>
 WADS 2011 </i>
<div id="absPB" style="display:none"><font face="Arial" size="3">
<p>
 We study the following load balancing problem on paths
(PB). There is a path containing n vertices. Every vertex i has an initial
load h i , and every edge (j, j + 1) has an initial load w j that it needs
to distribute among the two vertices that are its endpoints. The goal is
to distribute the load of the edges over the vertices in a way that will
make the loads of the vertices as balanced as possible (formally, mini-
mizing the sum of squares of loads of the vertices). This problem can be
solved in polynomial time, e.g, by dynamic programming. We present an
algorithm that solves this problem in time O(n log n).
As a mental aide in the design of our algorithm, we ﬁrst design a hy-
draulic apparatus composed of bins (representing vertices), tubes (rep-
resenting edges) that are connected between bins, cylinders within the
tubes that constrain the ﬂow of water, and valves that can close the con-
nections between bins and tubes. Water may be poured into the various
bins, to levels that correspond to the initial loads in the input to the PB
problem. When all valves are opened, the water ﬂows between bins (to
the extent that is feasible due to the cylinders) and stabilizes at levels
that are the correct output to the respective PB problem. Our algorithm
is based on a fast simulation of the behavior of this hydraulic apparatus,
when valves are opened one by one.

  </p></font>
</div></li>
<!-------------------------------------------------------------->

<li> <b>
Local Dynamics in Bargaining Networks via Random-Turn Games
  </b>[<a href="pubs/BargainingRTG.pdf">pdf</a>| <a   href = "#PR" onclick="toggle_visibility('absRTG');">Show/Hide  Abstract</a>]<br>
with Elisa Celis and Yuval Peres.
In Proc. <i>
WINE 2010
  </i>
  <div id="absRTG" style="display:none"><font face="Arial" size="3">
<p>
  We present a new technique for analyzing the rate of convergence
of local dynamics in bargaining networks. The technique reduces
balancing in a bargaining network to optimal play in a random-turn
game. We analyze this game using techniques from martingale and
Markov chain theory. We obtain a tight polynomial bound on the rate
of convergence for a nontrivial class of unweighted graphs (the previous
known bound was exponential). Additionally, we show this technique
extends naturally to many other graphs and dynamics.
  </p></font>
</div>
</li>

<li> <b>
Market Equilibrium with Transaction Costs
  </b>[<a href="pubs/mewtc.pdf">pdf</a>| <a   href = "#PR" onclick="toggle_visibility('absMEWTC');">Show/Hide  Abstract</a>]<br>
with Sourav Chakraborty and Chinmay Karande.
In Proc. <i>
WINE 2010
  </i>
  <div id="absMEWTC" style="display:none"><font face="Arial" size="3">
<p>
  Identical products being sold at different prices in different
locations is a common phenomenon. To model such scenarios, we supplement the classical Fisher market model by introducing {\em transaction costs}. For every buyer $i$ and good $j$, there is a transaction cost of $c_{ij}$; if the price of good $j$ is $p_j$, then the cost to the buyer $i$ {\em per unit} of $j$ is $p_j + c_{ij}$. The same good can thus be sold at different (effective) prices to different buyers. We provide a combinatorial algorithm that computes $\epsilon$-approximate equilibrium prices and allocations in $O\left(\frac{1}{\epsilon}(n+\log{m})mn\log(B/\epsilon)\right)$
operations - where $m$ is the number goods, $n$ is the number of buyers and $B$ is the sum of the budgets of all the buyers.
  </p></font>
</div>
</li>
<li> <b>
 An Online Multi-unit Auction with Improved Competitive Ratio
  </b>[<a href="pubs/OMUA.pdf">pdf</a> | <a   href = "#OMUA" onclick="toggle_visibility('absOMUA');">Show/Hide  Abstract</a>]<br>
with Sourav Chakraborty.
In Proc. <i>
WINE 2009.
  </i>
<div id="absOMUA" style="display:none"><font face="Arial" size="3">
<P>
  We improve the best known competitive ratio (from 1/4 to 1/2),
for the online multi-unit allocation problem,
where the objective is to maximize the single-price revenue.
Moreover, the competitive ratio of our algorithm tends to 1,
as the bid-profile tends to "smoothen".
This algorithm is used as a subroutine in designing truthful auctions
for the same setting: the allocation has to be done online,
while the payments can be decided at the end of the day.
Earlier, a reduction from  the auction design problem to the allocation problem
was known only for the unit-demand case.
We give a reduction for the general case when the bidders have
decreasing marginal utilities.
The problem is inspired by sponsored search auctions.
</p>
  </font>
</div>

</li>

<li> <b>
A Computational Theory of Awareness and Decision Making
  </b>[<a href="pubs/awareness.pdf">pdf</a> | <a   href = "#AWA" onclick="toggle_visibility('absAWA');">Show/Hide  Abstract</a>]<br>
with Lance Fortnow.
In Proc. <i>
 Theoretical Aspects of Rationality and Knowledge, TARK 2009
  </i>
<div id="absAWA" style="display:none"><font face="Arial" size="3">
<P>
  We exhibit a new computational-based definition of awareness,
informally that our level of unawareness of an object is the amount
of time needed to generate that object within a certain environment.
We give several examples to show this notion matches our intuition
in scenarios where one organizes, accesses and transfers
information. We also give a formal process-independent definition of
awareness based on Levin's universal enumeration.

We show the usefulness of computational awareness by showing how it
relates to decision making, and how others can manipulate our
decision making with appropriate advertising, in particular, we show
connections to sponsored search and brand awareness. Understanding
awareness can also help rate the effectiveness of various user
interfaces designed to access information.
  </P>
  </font>
</div>

</li>

<li> <b>
Market Equilibria in Polynomial time for
fixed number of goods or agents
  </b>[<a href="pubs/PLC.pdf">pdf</a> | <a   href = "#PLC" onclick="toggle_visibility('absPLC');">Show/Hide  Abstract</a>]<br>
with Ravi Kannan.
In Proc. <i>
FOCS 2008.
  </i>

<div id="absPLC" style="display:none"><font face="Arial" size="3">
<p> We consider markets in the classical Arrow-Debreu model. There are n
agents and m goods. Each buyer has a concave utility function
(of the bundle of goods he/she buys) and an initial bundle. At an
``equilibrium'' set of prices for goods, if each individual buyer
separately exchanges the initial bundle for an optimal bundle at
the set prices, the market clears, i.e., all goods are exactly
consumed. Classical theorems guarantee the existence of equilibria,
but computing them has been the subject of much recent research.
In the related area of Multi-Agent Games, much attention has been paid to
the complexity as well as algorithms.
While most general problems are
hard, polynomial time algorithms have been developed for restricted
classes of games, when one assumes  the
number of strategies is constant.
</p>
  <P>
For the Market Equilibrium problem, several important special cases of
utility functions have been tackled.
 Here we begin a program for this
problem similar to that for multi-agent games, where general utilities
are considered.  We begin by showing that if the utilities are
separable piece-wise linear concave (PLC) functions, and the number of
goods (or alternatively the number of buyers) is constant, then we can
compute an exact equilibrium in polynomial time. Our
technique for the constant number of goods is to decompose the space
of price vectors into cells using certain hyperplanes, so that in each
cell, each buyer's threshold marginal utility is known. Still, one
needs to solve a linear optimization problem in each cell.
We then show the main result - that for general
(non-separable) PLC utilities, an exact equilibrium can be found in
polynomial time provided the number of goods is constant. The starting
point of the algorithm is a ``cell-decomposition'' of the space of
price vectors using polynomial surfaces (instead of hyperplanes).
We use results from computational algebraic geometry to bound the
number of such cells.
For solving the problem inside each cell, we introduce and use a novel
LP-duality based method. We note that if the number of
buyers and agents both can vary, the problem is PPAD hard even for the
very special case of  PLC utilities such as Leontief utilities and separable PLC utilities.
</p>
  </font>
</div>
</li>

<li>
<b>
New Geometry-Inspired Relaxations and Algorithms for the Metric Steiner Tree Problem.
</b>
[<a href="pubs/steiner.pdf">pdf</a> | <a   href = "#STI" onclick="toggle_visibility('absSTI');">Show/Hide  Abstract</a>]<br>
with Deeparnab Chakrabarty, and Vijay Vazirani.
In <i> Math Programming (Series A)</i> Volume 122, Number 2 (April 2010).
(Preliminary  version in <I> IPCO 2008. </i>)
<div id="absSTI" style="display:none"><font face="Arial" size="3">
<P>
  Determining the integrality gap of the bidirected cut relaxation for the metric Steiner tree
problem, and exploiting it algorithmically, is a long-standing open problem. We use geometry
to define an LP whose dual is equivalent to this relaxation. This opens up the possibility of
using the primal-dual schema in a geometric setting for designing an algorithm for this problem.
Using this approach, we obtain a 4/3 factor algorithm and integrality gap bound for the case
of quasi-bipartite graphs; the previous best integrality gap upper bound being 3/2. We
also obtain a factor $sqrt{2}$ strongly polynomial algorithm for this class of graphs.
A key difficulty experienced by researchers in working with the bidirected cut relaxation
was that any reasonable dual growth procedure produces extremely unwieldy dual solutions.
A new algorithmic idea helps finesse this difficulty -  that of reducing the cost of certain edges
and constructing the dual in this altered instance - and this idea can be extracted into a new
technique for running the primal-dual schema in the setting of approximation algorithms.
  </P>
  </font>
</div>

</li>

<li>  <b>
On Computing the Distinguishing Numbers of Planar Graphs and Beyond: a Counting Approach
  </b>[<a href="pubs/dist.pdf">pdf</a> | <a   href = "#DIST" onclick="toggle_visibility('absDIST');">Show/Hide  Abstract</a>]<br>
with V. Arvind and Christine Cheng.
In <i>
SIAM Journal on Discrete Mathematics,  </i> vol. 22, no. 4 (October 2008), pp. 1297-1324.
<div id="absDIST" style="display:none"><font face="Arial" size="3">
<P>
  A vertex k-labeling of graph G is distinguishing if the only automorphism that preserves the labels
of G is the identity map. The distinguishing number of G, D(G), is the smallest integer k for which G
has a distinguishing k-labeling. In this paper, we apply the principle of inclusion-exclusion and develop
recursive formulas to count the number of inequivalent distinguishing k-labelings of a graph. Along the
way, we prove that the distinguishing number of a planar graph can be computed in time polynomial in
the size of the graph.
</p>
  </font>
</div>

</li>
<li> <b>
On the Equivalence of Competitive and Submodular markets
  </b>[<a href="pubs/competitive.pdf">pdf</a> | <a   href = "#COM" onclick="toggle_visibility('absCOM');">Show/Hide  Abstract</a>]<br>
with Deeparnab Chakrabarty.
In <I> Operations Research Letters,</i> vol. 37, no. 3, pp. 155 - 158, 2009.
Prelim. version in Proc. <i>
WINE 2007
  </i>
<div id="absCOM" style="display:none"><font face="Arial" size="3">
<P>
  In this paper, we study competitive markets - a market is
competitive if increasing the endowment of any one buyer does not in-
crease the equilibrium utility of any other buyer. In the Fisher setting,
competitive markets contain all markets with weak gross substitutabil-
ity (WGS), a property which enable efficient algorithms for equilibrium
computation.
We show that every uniform utility allocation (UUA) market which is
competitive, is a submodular utility allocation (SUA) market. Our result
provides evidence for the existence of efficient algoritheorems for the class
of competitive markets.
</P>
  </font>
</div>

</li>

<li><b>
Computing Market Equilibrium: Beyond Weak Gross Substitutes
  </b>[<a href="pubs/ApproxWGS.pdf">pdf</a> | <a   href = "#AWGS" onclick="toggle_visibility('absAWGS');">Show/Hide  Abstract</a>]<br>
with Chinmay Karande.
In Proc. <i>
WINE 2007
  </i>
<div id="absAWGS" style="display:none"><font face="Arial" size="3">
<P>The property of Weak Gross Substitutibility (WGS) of goods in a market has been found
to be conducive to efficient algorithms for finding equilibria. In this paper, we give a natural
definition of a $\delta$ approximate WGS property, and show that the auction algorithm of Garg and Kapoor
 can be extended to give an $\epsilon + \delta$  approximate equilibrium for markets with this
property.
</p>
  </font>
</div>

</li>
<li> <b>
New results on Rationality and Strongly Poylnomial Solvability in Eisenberg-Gale markets
  </b>[<a href="pubs/EG2.pdf">pdf</a> | <a   href = "#EG2" onclick="toggle_visibility('absEG2');">Show/Hide  Abstract</a>]<br>
with Deeparnab Chakrabarty and Vijay Vazirani.
In Proc. <i>
WINE 2006
  </i>
<div id="absEG2" style="display:none"><font face="Arial" size="3">
<P>
  We study the structure of EG(2) markets, the class of Eisenberg-Gale markets with
two agents. We prove that all markets in this class are rational and they admit strongly
polynomial algorithms whenever the polytope containing the set of feasible utilities of
the two agents can be described via a combinatorial LP. This helps resolve positively
the status of two markets left as open problems by Jain and Vazirani: the capacity allocation
market in a directed graph with two source-sink pairs and the network coding market
in a directed network with two sources.
Our algorithms for solving the corresponding nonlinear convex programs are
fundamentally different from those obtained by Jain and Vazirani; whereas they use the primal-
dual schema, we use a carefully constructed binary search.
</P>
  </font>
</div>


<li>
<b>
Integrality Gaps for Sparsest Cut and Minimum Linear Arrangement Problems
</b>[<a href="pubs/usc.pdf">pdf</a> | <a   href = "#USC" onclick="toggle_visibility('absUSC');">Show/Hide  Abstract</a>]<br>
with  Subhash A. Khot,  Rishi Saket and Nisheeth K. Vishnoi.
 In Proc.  <i>
STOC 2006.
</i>
<div id="absUSC" style="display:none"><font face="Arial" size="3">
<P>
  Arora, Rao and Vazirani
 showed that the standard semi-definite programming (SDP)
 relaxation of the sparsest cut problem with the  triangle
 inequality
 constraints has an integrality gap of $O(\sqrt{\log n})$. They
 conjectured that the gap is bounded from above by a constant. In this paper, we disprove
 this conjecture
 by constructing an $\Omega(\log \log n)$ integrality gap
 instance. Khot and Vishnoi had earlier disproved the
 non-uniform  version of this Conjecture.

A simple ``stretching'' of the integrality gap instance for the
sparsest cut problem serves as an $\Omega(\log \log n)$ integrality gap
instance for the  SDP relaxation of the Minimum Linear Arrangement problem. This
SDP relaxation was considered in Charikar et. al. and Feige and Lee, where it was shown that its integrality gap is bounded
from above by $O(\sqrt{\log n} \log \log n).$
  </p>

  </font>
</div>


</li>
</li>
<li> <b>
Price of Anarchy, Locality Gap, and
a Network Service Provider Game
  </b>[<a href="pubs/POA.pdf">pdf</a> | <a   href = "#POA" onclick="toggle_visibility('absPOA');">Show/Hide  Abstract</a>]<br>
with Naveen Garg, Rohit Khandekar,
 Vinayaka Pandit, Amin Saberi, and Vijay V. Vazirani.
In Proc. <i>
WINE 2005
  </i>
<div id="absPOA" style="display:none"><font face="Arial" size="3">
<P>
  In this paper, we define a network service provider game. We show that
the price of anarchy of the defined game can be bounded by analyzing
a local search heuristic for a related facility location
problem called the $k$-facility location problem. As a result, we show
that the $k$-facility location problem has a locality gap of 5. This
result is of interest on its own. Our result gives evidence to the
belief that the price of anarchy of certain games are related to
analysis of local search heuristics.
</P>
  </font>
</div>

</li>
<li> <b>
On the complexity of Hilbert's 17th
problem
  </b>[<a href="pubs/hilbert.pdf">pdf</a> | <a   href = "#HIL" onclick="toggle_visibility('absHIL');">Show/Hide  Abstract</a>]<br>
with Richard J. Lipton and Nisheeth Vishnoi.
In Proc. <i>
FSTTCS 2004.
  </i>
<div id="absHIL" style="display:none"><font face="Arial" size="3">
<P>
  Hilbert posed the following problem as the 17th in the list of 23 problems in his famous 1900 lecture:
 <i>Given a
multivariate polynomial that takes only non-negative values over
the reals, can it be represented as a sum of squares of rational
functions?</i>

In 1927, E.~Artin gave an affirmative answer to this question.
His result guaranteed the existence of such a  finite representation and
raised the following important question:
<i> What is the {\bf minimum number} of rational functions needed to represent
any non-negative $n$-variate, degree $d$  polynomial?</i>

In 1967, Pfister proved that  any $n$-variate non-negative
polynomial over the reals can be written as sum of squares of at most  $2^n$ rational functions.
In spite of a considerable effort by
mathematicians for over 75 years, it is <i> not </i> known
whether $n+2$ rational functions are sufficient!

In lieu of the lack of progress towards the resolution of this question, we initiate the study of  Hilbert's 17th problem from the  point
of view of Computational Complexity.
In this setting, the  following question is a natural relaxation:
<i> What is the {\bf descriptive complexity} of the sum of squares representation (as rational functions) of
a non-negative, $n$-variate, degree $d$  polynomial?</i>
We consider  arithmetic circuits as a natural representation of rational functions.
We are able to show, assuming a standard conjecture in complexity theory, that it is impossible that every non-negative, $n$-variate, degree four
polynomial can be represented as a sum of squares of a  small (polynomial in $n$) number of  rational functions, each of which has a  small size  arithmetic circuit (over the rationals) computing it.

<p>
Our result points to the direction that it is unlikely
that every non-negative, $n$-variate polynomial over the reals can be written as a sum of squares of a polynomial (in $n$)  number of rational functions. Further, relating to standard (and believed to be hard to prove) complexity-theoretic conjectures sheds some light on why it has been difficult for mathematicians to close the $n+2$ and $2^n$ gap. We hope that our line of work will play an important role in the resolution of this question.
  </p>
</p>

  </font>
</div>

</li>
<li>
<b>
The Spending Constraint Model for Market
Equilibrium: Algorithmic, Existence and Uniqueness results
</b>[<a href="pubs/sconstraint.pdf">pdf</a> | <a   href = "#SC" onclick="toggle_visibility('absSC');">Show/Hide  Abstract</a>]<br>
 with
Vijay V. Vazirani.
In Proc. <i>
STOC 2004.
</i>
<div id="absSC" style="display:none"><font face="Arial" size="3">
<P>
  The traditional model of market equilibrium supports impressive existence results, including the celebrated
  Arrow-Debreu Theorem. However, in this model, polynomial time
algorithms for computing (or approximating) equilibria are
known only for linear utility functions. We present a new,
and natural, model of market equilibrium that not only admits existence and uniqueness results paralleling those for
the traditional model but is also amenable to efficient algorithms.
</P>

  </font>
</div>

</li>
<li> <b>
An Improved Approximation Scheme for
Computing Arrow-Debreu Prices for the Linear Case
  </b>[<a href="pubs/adptas.pdf">pdf</a> | <a   href = "#AD" onclick="toggle_visibility('absAD');">Show/Hide  Abstract</a>]<br>
with Vijay Vazirani.
In Proc. <i>
FSTTCS 2003.
  </i>
<div id="absAD" style="display:none"><font face="Arial" size="3">
<P>
   Recently, Jain, Mahdian and Saberi
had given a FPTAS for the problem of computing a market
equilibrium in the Arrow-Debreu setting, when the utilities are linear functions. Their running
time depended on the size of the numbers representing the
utilities and endowments of the buyers. In this paper, we give a
strongly polynomial time approximation scheme for this problem.
 Our algorithm builds upon  the main ideas
behind the algorithm in Devanur et. al.
  </p>
  </font>
</div>

</li>

<!--
<li> <b>
Who's the Weakest Link?
  </b>[<a href="pubs/weakest.pdf">pdf</a> | <a   href = "#WL" onclick="toggle_visibility('absWL');">Show/Hide  Abstract</a>]<br>
with Richard J. Lipton, and Nisheeth Vishnoi.
In Proc. of <i> 2nd
International Symposium on Stochastic Algorithms: Foundations and
Applications,
SAGA 2003.
  </i>
<div id="absWL" style="display:none"><font face="Arial" size="3">
Abstract
  </font>
</div>

</li>
-->
<!-------------------------------------------------------------->
<li> <b>
Strategyproof cost-sharing Mechanisms
for Set Cover and Facility Location Games
  </b>[<a href="pubs/DMV.pdf">pdf</a> | <a   href = "#DMV" onclick="toggle_visibility('absDMV');">Show/Hide  Abstract</a>]<br>
with Milena Mihail and Vijay Vazirani.
<i> Decision Support Systems</i> 39 (March 2005), pp 11--22.
Prelim. version in Proc. <i>
ACM EC 2003
  </i>
<div id="absDMV" style="display:none"><font face="Arial" size="3">
<P> Strategyproof cost-sharing mechanisms, lying in the  core,
that recover $1/\alpha$ fraction of the cost, are
presented for the set cover and facility location games; $\alpha =
O(\log n)$ for the former and 1.861 for the latter. Our mechanisms
utilize approximation algorithms for these problems based
on the method of dual-fitting.
  </p>
  </font>
</div>

</li>
<!-------------------------------------------------------------->

<!-------------------------------------------------------------->
<li><b>
Market Equilibrium via a Primal-Dual-Type Algorithm
</b> [<a href="pubs/DPSV-JACM.pdf">pdf</a> | <a   href = "#DPSV" onclick="toggle_visibility('absDPSV');">Show/Hide  Abstract</a>]<br>
with Christos H. Papadimitriou, Amin Saberi and Vijay V.Vazirani.
 In The <I>Journal of the ACM</i>, vol. 55, no. 5 (October 2008),   pp 1--18.
Prelim version appeared in <i>FOCS 2002.</i>
<div id="absDPSV" style="display:none"><font face="Arial" size="3">
<P>
 We give the first polynomial time algorithm for exactly computing an equilibrium
for the linear utilities case of the market model defined by Fisher.
Our algorithm uses the primal-dual paradigm in the enhanced setting of KKT conditions
and convex programs. We pinpoint the added difficulty raised by this setting and the
manner in which our algorithm circumvents it.
  </P>
  </font>
</div>

</li>
<!-------------------------------------------------------------->

</font></ul>

<!-- begin comment
<font face="Trebuchet MS" size="3"></font>


          <table height="30"> <tbody><tr><td width="100%"> </td></tr></tbody></table>

<table width="100%" bgcolor="#dbeaf5" border="0" cellpadding="5" cellspacing="0">
<tbody><tr><td align="left">
<font face="Arial" size="+1"> <a name="pub"> Invited Talks </a> </font>
</td></tr></tbody></table>

<ul>
<font face="Trebuchet MS" size="3">

<li>
<b>
New Geometric Relaxations for the Steiner Tree Problem
     and their Algorithmic Consequences
</b>
<br> in the
<i> Stanford Algorithms Seminar</i>,
November 2006.

</li><li>
<b>
Market Equilibrium: Models and Algorithms
</b><br>
In the <i>
Cornell Theory Seminar,
</i>
March 2006


</li><li> <b>
Price of Anarchy, Locality Gap, and a Network
Service Provider Game
</b>
<br>
 In   <i>
INFORMS,
</i>
2004.

</li><li>
<b>
Market Equilibrium: Algorithms for the Linear Case</b>
<br>
In <i>
Dagstuhl Seminar on
Algorithmic Game Theory and the Internet</i>,
July  2003.

</li></font></ul>



<font face="Trebuchet MS" size="3"></font>
</div></td>
</tr></tbody></table>

end all the way here -->

</div></body></html>
