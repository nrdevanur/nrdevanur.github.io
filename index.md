---
title: Nikhil R. Devanur
---

::: {align="left"}
  --
  --
:::

  --
  --

  ------------------
  Nikhil R Devanur
  ------------------

  --
  --

+:---------------------------------:+-----------------------------------+
| ![](files/Profile2019.jpg)        |   --                              |
|                                   |   --                              |
|                                   |                                   |
|                                   | Bio: Nikhil R. Devanur is a       |
|                                   | Principal Scientist at Amazon     |
|                                   | working on [Sponsored             |
|                                   | Products](https://advertis        |
|                                   | ing.amazon.com/products/sponsored |
|                                   | -products/?ref_=a20m_us_gw_splm). |
|                                   | Previously, he was the manager of |
|                                   | the [Algorithms                   |
|                                   | group](h                          |
|                                   | ttps://www.microsoft.com/en-us/re |
|                                   | search/group/algorithms-redmond/) |
|                                   | in [Microsoft                     |
|                                   | Research]                         |
|                                   | (http://research.microsoft.com/), |
|                                   | Redmond.                          |
|                                   |                                   |
|                                   | He is interested in what he calls |
|                                   | Automated Economics, which        |
|                                   | studies the question of how       |
|                                   | technology can be used to improve |
|                                   | the efficiency of economic        |
|                                   | systems. His other interest is in |
|                                   | Algorithms: he is interested in   |
|                                   | designing algorithms that are     |
|                                   | faster, simpler, work online or   |
|                                   | in a distributed fashion, for     |
|                                   | some of the basic combinatorial   |
|                                   | optimization problems.            |
|                                   |                                   |
|                                   | Contact: Iam\@nikhildevanur.com   |
|                                   |                                   |
|                                   |   --                              |
|                                   |   --                              |
|                                   |                                   |
|                                   | Mentees (Interns)                 |
|                                   |                                   |
|                                   | -   Ben Birnbaum, Flatiron Healrh |
|                                   | -   [Balu                         |
|                                   |     Sivan,](htt                   |
|                                   | p://pages.cs.wisc.edu/~balu2901/) |
|                                   |     Google Research               |
|                                   | -   [Zhiyi                        |
|                                   |     Hu                            |
|                                   | ang,](http://i.cs.hku.hk/~zhiyi/) |
|                                   |     University of Hong Kong       |
|                                   | -   [Jamie                        |
|                                   |     Morgenster                    |
|                                   | n,](http://jamiemorgenstern.com/) |
|                                   |     Georgia Tech                  |
|                                   | -   [Janardhan                    |
|                                   |                                   |
|                                   | Kulkarni,](https://www.microsoft. |
|                                   | com/en-us/research/people/jakul/) |
|                                   |     Microsoft Research            |
|                                   | -   [Alex                         |
|                                   |     Psomas,]                      |
|                                   | (http://www.cs.cmu.edu/~cpsomas/) |
|                                   |     CMU                           |
|                                   | -   [Rad                          |
|                                   |     Niazadeh,]                    |
|                                   | (http://www.cs.cornell.edu/~rad/) |
|                                   |     Stanford                      |
|                                   | -   [Sadra                        |
|                                   |     Yazdanbod,](htt               |
|                                   | p://www.cc.gatech.edu/~syazdanb/) |
|                                   |     Google                        |
|                                   | -   [Kira                         |
|                                   |     Goldner,](http://ho           |
|                                   | mes.cs.washington.edu/~kgoldner/) |
|                                   |     University of Washington      |
|                                   | -   [Thodoris                     |
|                                   |     Lykouris,](htt                |
|                                   | p://www.cs.cornell.edu/~teddlyk/) |
|                                   |     Cornell University            |
|                                   | -   [Jakub                        |
|                                   |     Tarnaws                       |
|                                   | ki,](http://jakub.tarnawski.org/) |
|                                   |     EPFL                          |
+-----------------------------------+-----------------------------------+

::: {align="left"}
  --
  --

[News]{#pubselect}
:::

-   Fall 2019: I moved to Amazon as a Principal Scientist. I will be
    part of the [Sponsored
    Products](https://advertising.amazon.com/products/sponsored-products/?ref_=a20m_us_gw_splm)
    team.
-   Spring 2019: We are hiring! Please
    [apply](%20https://www.microsoft.com/en-us/research/group/algorithms-redmond/#!opportunities).
-   Spring 2017: I now manage the newly created [Algorithms
    group](https://www.microsoft.com/en-us/research/group/algorithms-redmond/)
    in Micrsoft Research, Redmond.
-   I am co-teaching (with Anna Karlin) a [course on Algorithms and
    Uncertainty](https://courses.cs.washington.edu/courses/cse522/17sp/)
    at UW this spring quarter, 2017.
-   I am the co-Program Committee Chair of
    [WINE 2017.](http://lcm.csa.iisc.ernet.in/wine2017/)
-   I am organizing an [ACM EC Workshop on Economic Aspects of Cloud
    Computing](http://wecc.azurewebsites.net/). Submission deadline is
    May 17th, 2016.
-   I am the Program Committee Chair of [APPROX
    2014](http://cui.unige.ch/tcs/random-approx/2014/index.php) .
-   I organized a [workshop on Online matching at
    STOC](https://sites.google.com/site/onlinematchingstoc/home) in Palo
    Alto on June 1st 2013.
-   I gave a tutorial on [Prior-Robust Optimization at
    EC](http://www.sigecom.org/ec13/schedule_tutorials.html) in
    Philadelphia on June 16 2013.
-   I taught a [course on online
    algorithms](OnlineAlgoCourse/index1.html) at UW this winter
    quarter, 2013.

::: {align="left"}
  --
  --

[Manuscripts]{#pubselect}
:::

-   **A new auction format for IPL players auctions**
    \[[pdf](pubs/IPLDraftAuctionsv3.1.pdf)\].
-   [DBLP
    page](http://www.informatik.uni-trier.de/~ley/pers/hd/d/Devanur:Nikhil_R=)
-   [Papers on
    Arxiv](https://arxiv.org/search/?query=nikhil+devanur&searchtype=author&abstracts=hide&order=-announced_date_first&size=50)

::: {align="left"}
  --
  --

[Selected Recent Publications]{#pubselect}
:::

**2021**

- **Proportional Dynamics in Exchange Economies.**\
with Simina Br^anzei, and Yuval Rabani.
 In Proc. of *ACM EC 2021*.
 - **Designing a Combinatorial Financial Options Market.**\
 with Xintong Wang, David M. Pennock, David M. Rothschild, Biaoshuai Tao, and Michael P. Wellman.
 In Proc. of *ACM EC 2021*.
 - **Static pricing for multi-unit prophet inequalities.**\
 with Shuchi Chawla, and Thodoris Lykouris. In Proc. of *WINE 2021*.

**2020**

- **Blink: Fast and Generic Collectives for Distributed ML.**\
 with Guanhua Wang, Shivaram Venkataraman, Amar Phanishayee, Jorgen Thelin, and Ion Stoica.
 In Proc. of *MLSys 2020*.
 - **Efficient Algorithms for Device Placement of DNN Graph Operators.**\
 with Jakub Tarnawski, Amar Phanishayee, Divya Mahajan, and Fanny Nina Paravecino.
 In Proc. of *NeurIPS 2020*.
- **Optimal Mechanism Design for Single-Minded Agents.** \
with Kira Goldner, Raghuvansh R. Saxena, Ariel Schvartzman, and S. Matthew Weinberg.
 In Proc. of *ACM EC 2020*.
- **Algorithmic Price Discrimination.**\
with Rachel Cummings, Zhiyi Huang, and Xiangning Wang.
In Proc. of *SODA 2020*.

**2019**

-   **Simple and Approximately Optimal Pricing for Proportional
    Complementarities.** \[[arXiv
    pdf](https://arxiv.org/pdf/1909.00788)\| [Show/Hide
    Abstract](#PC)\].\
    with Yang Cai, Kira Goldner, and R. Preston McAfee. In Proc. *EC
    2019*.
    ::: {#absPC style="display:none"}
    We study a new model of complementary valuations, which we call
    \"proportional complementarities.\'\' In contrast to common models,
    such as hypergraphic valuations, in our model, we do not assume that
    the extra value derived from owning a set of items is independent of
    the buyer\'s base valuations for the items. Instead, we model the
    complementarities as proportional to the buyer\'s base valuations,
    and these proportionalities are known market parameters. Our goal is
    to design a simple pricing scheme that, for a single buyer with
    proportional complementarities, yields approximately optimal
    revenue. We define a new class of mechanisms where some number of
    items are given away for free, and the remaining items are sold
    separately at inflated prices. We find that the better of such a
    mechanism and selling the grand bundle earns a 12-approximation to
    the optimal revenue for pairwise proportional complementarities.
    This confirms the intuition that items should not be sold completely
    separately in the presence of complementarities. In the more general
    case, a buyer has a maximum of proportional positive hypergraphic
    valuations, where a hyperedge in a given hypergraph describes the
    boost to the buyer\'s value for item i given by owning any set of
    items T in addition. The maximum-out-degree of such a hypergraph is
    d, and k is the positive rank of the hypergraph. For valuations
    given by these parameters, our simple pricing scheme is an
    O(min{d,k})-approximation.
    :::
-   **PipeDream: Generalized Pipeline Parallelism for DNN Training**
    \[[Show/Hide Abstract](#PPD)\].\
    with Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek
    Seshadri,,Greg Ganger, Phil Gibbons, Matei Zaharia. In Proc. *SOSP
    2019*.
    ::: {#absPPD style="display:none"}
    DNN training is extremely time-consuming, necessitating efficient
    multi-accelerator parallelization. Current approaches to paralleliz-
    ing training primarily use intra-batch parallelization, where a
    single iteration of training is split over the available workers,
    but suffer from diminishing returns at higher worker counts. We
    present PipeDream, a system that adds inter-batch pipelining to
    intra-batch parallelism to further improve parallel training
    throughput, help- ing to better overlap computation with
    communication and reduce the amount of communication when possible.
    PipeDream versions model parameters for backward pass correctness,
    schedules for- ward and backward passes of different minibatches
    concurrently on different workers to keep workers well utilized, and
    systemati- cally partitions DNN layers among workers to balance work
    and minimize communication. Extensive experimentation with a range
    of DNN tasks, models, and hardware configurations shows that
    PipeDream trains models to high accuracy up to 5.28x faster than
    commonly used inter-batch parallelism techniques.
    :::

**2018**

-   **A New Class of Combinatorial Markets with Covering Constraints:
    Algorithms and Applications** \[[arXiv
    pdf](https://arxiv.org/pdf/1511.08748.pdf)\| [Show/Hide
    Abstract](#CME)\].\
    with Jugal Garg, Ruta Mehta, Vijay V. Vazirani, Sadra Yazdanbod. In
    Proc. *SODA 2018*.
    ::: {#absCME style="display:none"}
    We introduce a new class of combinatorial markets in which agents
    have covering constraints over resources required and are interested
    in delay minimization. Our market model is applicable to several
    settings including scheduling, cloud computing, and communicating
    over a network. This model is quite different from the traditional
    models, to the extent that neither do the classical equilibrium
    existence results seem to apply to it nor do any of the efficient
    algorithmic techniques developed to compute equilibria seem to apply
    directly. We give a proof of existence of equilibrium and a
    polynomial time algorithm for finding one, drawing heavily on
    techniques from LP duality and submodular minimization. We observe
    that in our market model, the set of equilibrium prices could be a
    connected, non-convex set. To the best of our knowledge, this is the
    first natural example of the phenomenon where the set of solutions
    could have such complicated structure, yet there is a combinatorial
    polynomial time algorithm to find one. Finally, we show that our
    model inherits many of the fairness properties of traditional
    equilibrium models.
    :::
-   **Truthful Multi-Parameter Auctions with Online Supply: an
    Impossible Combination** \[[arXiv
    pdf](https://arxiv.org/pdf/1511.03699.pdf)\| [Show/Hide
    Abstract](#TMOA)\].\
    with Balasubramanian Sivan and Vasilis Syrgkanis. In Proc. *SODA
    2018*.
    ::: {#absTMOA style="display:none"}
    We study a basic auction design problem with online supply. There
    are two unit-demand bidders and two types of items. The first item
    type will arrive first for sure, and the second item type may or may
    not arrive. The auctioneer has to decide the allocation of an item
    immediately after each item arrives, but is allowed to compute
    payments after knowing how many items arrived. For this problem we
    show that there is no deterministic truthful and individually
    rational mechanism that, even with unbounded computational
    resources, gets any finite approximation factor to the optimal
    social welfare.
    :::
-   **Bubble Execution: Resource-aware Reliable Analytics at Cloud
    Scale.** \[[pdf](pubs/Bubble_with_ack.pdf)\| [Show/Hide
    Abstract](#BE)\].\
    with Zhicheng Yin, Jin Sun, Ming Li, Jaliya Ekanayake, Haibo Lin,
    Marc Friedman, Jose A. Blakeley and Clemens A. Szyperski. In Proc.
    *VLDB 2018*.
    ::: {#absBE style="display:none"}
    Enabling interactive data exploration at cloud scale requires
    minimizing end-to-end query execution latency, while guar- anteeing
    fault tolerance, and query execution under resource- constraints.
    Typically, such a query execution involves or- chestrating the
    execution of hundreds or thousands of re- lated tasks on cloud scale
    clusters. Without any resource constraints, all query tasks can be
    scheduled to execute si- multaneously (gang scheduling) while
    connected tasks stream data between them. When the data size
    referenced by a query increases, gang scheduling may be
    resource-wasteful or un-satisﬁable with a limited, per-query
    resource budget. This paper introduces Bubble Execution, a new query
    processing framework for interactive workloads at cloud scale, that
    balances cost-based query optimization, fault tolerance, optimal
    resource management, and execution orchestration. Bubble execution
    involves dividing a query execution graph into a collection of query
    sub-graphs (bubbles), and scheduling them within a per-query
    resource budget. The query operators (tasks) inside a bubble stream
    data between them while fault tolerance is handled by persisting
    temporary results at bubble boundaries. Our implementation enhances
    our JetScope service, for interactive workloads, deployed in
    production clusters at Microsoft. Experiments with TPC-H queries
    show that bubble execution can reduce resource usage significantly
    in the presence of failures while maintaining performance
    competitive with gang execution.
    :::

**2017**

-   **Stability of Service under Time-of-Use Pricing** \[ [arXiv
    pdf](https://arxiv.org/pdf/1704.02364.pdf) \| [Show/Hide
    Abstract](#SOS)\]\
    with Shuchi Chawla, Alexander E. Holroyd, Anna Karlin, James Martin
    and Balasubramanian Sivan. In Proc. *STOC 2017*
    ::: {#absSOS style="display:none"}
    We consider \"time-of-use\" pricing as a technique for matching
    supply and demand of temporal resources with the goal of maximizing
    social welfare. Relevant examples include energy, computing
    resources on a cloud computing platform, and charging stations for
    electric vehicles, among many others. A client/job in this setting
    has a window of time during which he needs service, and a particular
    value for obtaining it. We assume a stochastic model for demand,
    where each job materializes with some probability via an independent
    Bernoulli trial. Given a per-time-unit pricing of resources, any
    realized job will first try to get served by the cheapest available
    resource in its window and, failing that, will try to find service
    at the next cheapest available resource, and so on. Thus, the
    natural stochastic fluctuations in demand have the potential to lead
    to cascading overload events. Our main result shows that setting
    prices so as to optimally handle the expected demand works well:
    with high probability, when the actual demand is instantiated, the
    system is stable and the expected value of the jobs served is very
    close to that of the optimal offline algorithm.
    :::
-   **Truth and Regret in Online Scheduling** \[ [arXiv
    pdf](https://arxiv.org/pdf/1703.00484.pdf) \| [Show/Hide
    Abstract](#TROS)\]\
    with Shuchi Chawla, Janardhan Kulkarni, Rad Niazadeh. In Proc. *EC
    2017*
    ::: {#absTROS style="display:none"}
    We consider a scheduling problem where a cloud service provider has
    multiple units of a resource available over time. Selfish clients
    submit jobs, each with an arrival time, deadline, length, and value.
    The service provider\'s goal is to implement a truthful online
    mechanism for scheduling jobs so as to maximize the social welfare
    of the schedule. Recent work shows that under a stochastic
    assumption on job arrivals, there is a single-parameter family of
    mechanisms that achieves near-optimal social welfare. We show that
    given any such family of near-optimal online mechanisms, there
    exists an online mechanism that in the worst case performs nearly as
    well as the best of the given mechanisms. Our mechanism is truthful
    whenever the mechanisms in the given family are truthful and prompt,
    and achieves optimal (within constant factors) regret. We model the
    problem of competing against a family of online scheduling
    mechanisms as one of learning from expert advice. A primary
    challenge is that any scheduling decisions we make affect not only
    the payoff at the current step, but also the resource availability
    and payoffs in future steps. Furthermore, switching from one
    algorithm (a.k.a. expert) to another in an online fashion is
    challenging both because it requires synchronization with the state
    of the latter algorithm as well as because it affects the incentive
    structure of the algorithms. We further show how to adapt our
    algorithm to a non-clairvoyant setting where job lengths are unknown
    until jobs are run to completion. Once again, in this setting, we
    obtain truthfulness along with asymptotically optimal regret (within
    poly-logarithmic factors).
    :::
-   **Convex Program Duality, Fisher Markets, and Nash Social Welfare**
    \[[arXiv pdf](https://arxiv.org/pdf/1609.06654.pdf) \| [Show/Hide
    Abstract](#CP)\].\
    with Richard Cole, Vasilis Gkatzelis, Kamal Jain, Tung Mai, Vijay V.
    Vazirani and Sadra Yazdanbod. In Proc. *EC 2017*
    ::: {#absCP style="display:none"}
    We study Fisher markets and the problem of maximizing the Nash
    social welfare (NSW), and show several closely related new results.
    In particular, we obtain:

    -   A new integer program for the NSW maximization problem whose
        fractional relaxation has a bounded integrality gap. In
        contrast, the natural integer program has an unbounded
        integrality gap.
    -   An improved, and tight, factor 2 analysis of the algorithm of
        \[7\]; in turn showing that the integrality gap of the above
        relaxation is at most 2. The approximation factor shown by \[7\]
        was 2e\^(1/e) \~ 2.89.
    -   A lower bound of e\^(1/e) \~ 1.44 on the integrality gap of this
        relaxation.
    -   New convex programs for natural generalizations of linear Fisher
        markets and proofs that these markets admit rational equilibria.

    These results were obtained by establishing connections between
    previously known disparate results, and they help uncover their
    mathematical underpinnings. We show a formal connection between the
    convex programs of Eisenberg and Gale and that of Shmyrev, namely
    that their duals are equivalent up to a change of variables. Both
    programs capture equilibria of linear Fisher markets. By adding
    suitable constraints to Shmyrev\'s program, we obtain a convex
    program that captures equilibria of the spending-restricted market
    model defined by \[7\] in the context of the NSW maximization
    problem. Further, adding certain integral constraints to this
    program we get the integer program for the NSW mentioned above. The
    basic tool we use is convex programming duality. In the special case
    of convex programs with linear constraints (but convex objectives),
    we show a particularly simple way of obtaining dual programs,
    putting it almost at par with linear program duality. This simple
    way of finding duals has been used subsequently for many other
    applications.
    :::
-   **Optimal Multi-Unit Mechanisms with Private Demands** \[ [arXiv
    pdf](https://arxiv.org/pdf/1704.05027.pdf) \| [Show/Hide
    Abstract](#MUP)\]\
    with Nima Haghpanah, Christos-Alexandros Psomas. In Proc. *EC 2017*
    ::: {#absMUP style="display:none"}
    In the multi-unit pricing problem, multiple units of a single item
    are for sale. A buyer\'s valuation for n units of the item is
    v\*min{n,d}, where the per unit valuation v and the capacity d are
    private information of the buyer. We consider this problem in the
    Bayesian setting, where the pair (v,d) is drawn jointly from a given
    probability distribution. In the unlimited supply setting, the
    optimal (revenue maximizing) mechanism is a pricing problem, i.e.,
    it is a menu of lotteries. In this paper we show that under a
    natural regularity condition on the probability distributions, which
    we call decreasing marginal revenue, the optimal pricing is in fact
    deterministic. It is a price curve, offering i units of the item for
    a price of p\_i, for every integer i. Further, we show that the
    revenue as a function of the prices p\_i is a concave function,
    which implies that the optimum price curve can be found in
    polynomial time. This gives a rare example of a natural
    multi-parameter setting where we can show such a clean
    characterization of the optimal mechanism. We also give a more
    detailed characterization of the optimal prices for the case where
    there are only two possible demands.
    :::
-   **Online Auctions and Multi-scale Online Learning** \[
    [pdf](pubs/msol-jmlr.pdf) \| [Show/Hide Abstract](#MSOL)\]\
    with Sebastien Bubeck, Zhiyi Huang and Rad Niazadeh. In Proc. *EC
    2017*
    ::: {#absMSOL style="display:none"}
    We consider revenue maximization in online auctions and pricing. A
    seller sells an identical item in each period to a new buyer, or a
    new set of buyers. For the online posted pricing problem, we show
    regret bounds that scale with the best fixed price, rather than the
    range of the values. We also show regret bounds that are almost
    scale free, and match the offine sample complexity, when comparing
    to a benchmark that requires a lower bound on the market share.
    These results are obtained by generalizing the classical learning
    from experts and multi-armed bandit problems to their multi-scale
    versions. In this version, the reward of each action is in a
    different range, and the regret w.r.t. a given action scales with
    its own range, rather than the maximum range.
    :::
-   **The optimal mechanism for selling to a budget constrained buyer:
    the general case** \[ [pdf](pubs/sib-ec.pdf) \| [Show/Hide
    Abstract](#SIB)\]\
    with Matt Weinberg. In Proc. *EC 2017*
    ::: {#absSIB style="display:none"}
    We consider a revenue-maximizing seller with a single item facing a
    single buyer with a private budget. The (value, budget) pair is
    drawn from an arbitrary and possibly correlated distribution. We
    characterize the optimal mechanism in such cases, and quantify the
    amount of price discrimination that might be present. For example,
    there could be up to 3\*2\^(k-1)-1 distinct non-trivial menu options
    in the optimal mechanism for such a buyer with k distinct possible
    budgets (compared to k if the marginal distribution of values
    conditioned on each budget has decreasing marginal revenue \[Che and
    Gale, 2000\], or 2 if there is an arbitrary distribution and one
    possible budget \[Chawla et al., 2011\]). Our approach makes use of
    the duality framework of Cai et al. \[2016\], and duality techniques
    related to the \"FedEx Problem\" of Fiat et al. \[2016\]. In
    contrast to \[Fiat et al., 2016\] and other prior work, we
    characterize the optimal primal/dual without nailing down an
    explicit closed form.
    :::

**2016**

-   **Linear Contextual Bandits with Knapsacks** \[ [NIPS
    pdf](pubs/NIPSLinContextualmain.pdf) \|
    [Supplement](pubs/NIPSLinContextualSupplement.pdf) \| [Show/Hide
    Abstract](#LCB)\]\
    with Shipra Agrawal. In Proc. *NIPS 2016*
    ::: {#absLCB style="display:none"}
    We consider the linear contextual bandit problem with resource
    consumption, in addition to reward generation. In each round, the
    outcome of pulling an arm is a reward as well as a vector of
    resource consumptions. The expected values of these outcomes depend
    linearly on the context of that arm. The budget/capacity constraints
    require that the total consumption doesn't exceed the budget for
    each resource. The objective is once again to maximize the total
    reward. This problem turns out to be a common generalization of
    classic linear contextual bandits (linContextual), bandits with
    knapsacks (BwK), and the online stochastic packing problem (OSPP).
    We present algorithms with near-optimal regret bounds for this
    problem. Our bounds compare favorably to results on the unstruc-
    tured version of the problem where the relation between the contexts
    and the outcomes could be arbitrary, but the algorithm only competes
    against a ﬁxed set of policies accessible through an optimization
    oracle. We combine techniques from the work on linContextual, BwK
    and OSPP in a nontrivial manner while also tackling new difﬁculties
    that are not present in any of these special cases.
    :::
-   **The Sample Complexity of Auctions with Side Information** \[[arXiv
    pdf](http://arxiv.org/pdf/1511.02296.pdf)\| [Show/Hide
    Abstract](#SCA)\]\
    with Zhiyi Huang and Christos-Alexandros Psomas. In Proc. *STOC
    2016*
    ::: {#absSCA style="display:none"}
    Traditionally, the Bayesian optimal auction design problem has been
    considered either when the bidder values are i.i.d, or when each
    bidder is individually identifiable via her value distribution. The
    latter is a reasonable approach when the bidders can be classified
    into a few categories, but there are many instances where the
    classification of bidders is a continuum. For example, the
    classification of the bidders may be based on their annual income,
    their propensity to buy an item based on past behavior, or in the
    case of ad auctions, the click through rate of their ads. We
    introduce an alternate model that captures this aspect, where
    bidders are a priori identical, but can be distinguished based
    (only) on some side information the auctioneer obtains at the time
    of the auction. We extend the sample complexity approach of
    Dhangwatnotai et al. and Cole and Roughgarden to this model and
    obtain almost matching upper and lower bounds. As an aside, we
    obtain a revenue monotonicity lemma which may be of independent
    interest. We also show how to use Empirical Risk Minimization
    techniques to improve the sample complexity bound of Cole and
    Roughgarden for the non-identical but independent value distribution
    case.
    :::
-   **A Duality Based Unified Approach to Bayesian Mechanism Design**
    \[[pdf](pubs/DualityAuctions.pdf)\| [Show/Hide Abstract](#DBMD)\]\
    with Yang Cai and Matt Weinberg. In Proc. *STOC 2016*
    ::: {#absDBMD style="display:none"}
    We provide a unified view of many recent exciting developments in
    Bayesian mechanism design, including the black-box reductions of Cai
    et. al., simple mechanisms for additive buyers \[Hart and Nisan, Li
    and Yao, Babaioff et al.\], and posted-price mechanisms for
    unit-demand buyers \[Chawla et al., Kleinberg and Weinberg\].
    Additionally, we show that viewing these three previously disjoint
    lines of work through the same lens allows us to improve upon each
    in several directions. First, our work provides a new and
    transparent duality framework for Bayesian mechanism design, which
    naturally accommodates multiple agents, and arbitrary objectives and
    feasibility constraints. Using this, we prove that either a
    posted-price mechanism, or the VCG mechanism with per-bidder entry
    fees is a constant-factor approximation to the optimal Bayesian IC
    mechanism whenever buyers are unit-demand or additive, unifying
    previous breakthroughs of Chawla et al. and Yao. In addition, we
    improve the approximation factor in Yao\'s work from 69 to 8.
    Finally, we show that this view also leads to improved structural
    characterizations in the Cai et. al. framework.
    :::
-   **An efficient algorithm for contextual bandits with knapsacks, and
    an extension to concave objectives** \[[arXiv
    pdf](http://arxiv.org/pdf/1506.03374.pdf)\| [Show/Hide
    Abstract](#CBwK)\]\
    with Shipra Agrawal and Lihong Li. In Proc. *COLT 2016*
    ::: {#absCBwK style="display:none"}
    We consider a contextual version of multi-armed bandit problem with
    global knapsack constraints. In each round, the outcome of pulling
    an arm is a scalar reward and a resource consumption vector, both
    dependent on the context, and the global knapsack constraints
    require the total consumption for each resource to be below some
    pre-fixed budget. The learning agent competes with an arbitrary set
    of context-dependent policies. This problem was introduced by
    Badanidiyuru et al., who gave a computationally inefficient
    algorithm with near optimal regret bounds for it. We give a
    computationally efficient algorithm for this problem with slightly
    better regret bounds, by generalizing the approach of Agarwal et al.
    for the non-constrained version of the problem. The computational
    time of our algorithm scales logarithmically in the size of the
    policy space. This answers the main open question of Badanidiyuru et
    al. We also extend our results to a variant where there are no
    knapsack constraints but the objective is an arbitrary Lipschitz
    concave function of the sum of outcome vectors.
    :::
-   **ProjecToR: Agile Reconfigurable Datacenter Interconnect** \[
    [pdf](pubs/projector-sigcomm-cr) \| [Show/Hide Abstract](#CBwK)\]\
    with M. Ghobadi, R. Mahajan, A. Phanishayee, H. Rastegarfar, P.
    Blanche, M. Glick, D. Kilper, J. Kulkarni and G. Ranade. In Proc.
    *SIGCOMM 2016*
    ::: {#absPTOR style="display:none"}
    We explore a radically different approach for building data center
    interconnects\--using free-space optics between racks, it enables
    all rack-pairs to communicate via direct links and can reconfigure
    such links within 12us. Our approach uses a digital micromirror
    device (DMD) and mirror assembly combination as a transmitter and a
    photodetector on top of the rack as a receiver. Transmitters and
    receivers in our interconnect can be dynamically linked in billions
    of ways. We develop topology construction and routing methods to
    exploit this flexibility, including a new flow scheduling algorithm
    that is a constant factor approximation to the offline optimal
    solution. We build a small prototype that points to the feasibility
    of our approach. Simulations and analysis show that, for realistic
    data center workloads, it can improve mean flow completion time by
    30-95%, while reducing cost by 25-40%.
    :::
-   **Multi-Score Position Auctions** \[[pdf](pubs/DSA.pdf)\| [Show/Hide
    Abstract](#DSA)\]\
    with Denis X. Charles and Balasubramanian Sivan. In Proc.
    *WSDM 2016.*
    ::: {#absDSA style="display:none"}
    In this paper we propose a general family of position auctions used
    in paid search, which we call multi-score position auctions. These
    auctions contain the GSP auction and the GSP auction with squashing
    as special cases. We show experimentally that these auctions contain
    special cases that perform better than the GSP auction with
    squashing, in terms of revenue, and the number of clicks on ads. In
    particular, we study in detail the special case that squashes the
    first slot alone and show that this beats pure squashing (which
    squashes all slots uniformly). We study the equilibria that arise in
    this special case to examine both the first order and the second
    order effect of moving from the squashing-all-slots auction to the
    squash-only-the-top-slot auction. For studying the second order
    effect, we simulate auctions using the value-relevance correlated
    distribution suggested in Lahaie and Pennock \[2007\]. Since this
    distribution is derived from a study of value and relevance
    distributions in Yahoo! we believe the insights derived from this
    simulation to be valuable. For measuring the first order effect, in
    addition to the said simulation, we also conduct experiments using
    auction data from Bing over several weeks that includes a random
    sample of all auctions.
    :::
-   **Simple Pricing Schemes For Consumers With Evolving Values**
    \[[pdf](pubs/ppp.pdf)\| [Show/Hide Abstract](#PPP)\]\
    with Shuchi Chawla, Anna Karlin and Balasubramanian Sivan. In Proc.
    *SODA 2016.*
    ::: {#absPPP style="display:none"}
    We consider a pricing problem where a buyer is interested in
    purchasing/using a good, such as an app or music or software,
    repeatedly over time. The consumer discovers his value for the good
    only as he uses it, and the value evolves with each use. Optimizing
    for the seller\'s revenue in such dynamic settings is a complex
    problem and requires assumptions about how the buyer behaves before
    learning his future value(s), and in particular, how he reacts to
    risk. We explore the performance of a class of pricing mechanisms
    that are extremely simple for both the buyer and the seller to use:
    the buyer reacts to prices myopically without worrying about how his
    value evolves in the future; the seller needs to optimize for
    revenue over a space of only two parameters, and can do so without
    knowing the buyer\'s risk profile or fine details of the value
    evolution process. We present simple-versus-optimal type results,
    namely that under certain assumptions, simple pricing mechanisms of
    the above form are approximately optimal *regardless of the buyer\'s
    risk profile* . Our results assume that the buyer\'s value per usage
    evolves as a martingale. For our main result, we consider pricing
    mechanisms in which the seller offers the product for free for a
    certain number of uses, and then charges an appropriate fixed price
    per usage. We assume that the buyer responds by buying the product
    for as long as his value exceeds the fixed price. Importantly, the
    buyer does not need to know anything about how his future value will
    evolve, only how much he wants to use the product *right now* .
    Regardless of the buyers\' initial value, our pricing captures as
    revenue a constant fraction of the total value that the buyers
    accumulate in expectation over time.
    :::

**2015**

-   **Speed Scaling in the Non-clairvoyant Model**
    \[[pdf](pubs/spaa035-azarA.pdf)\| [Show/Hide Abstract](#NCS)\]\
    with Yossi Azar, Zhiyi Huang and Debmalya Panigrahi. In Proc.
    *SPAA 2015.* Winner of the **Best Paper award.**
    ::: {#absNCS style="display:none"}
    In recent years, there has been a growing interest in speed scaling
    algorithms, where a set of jobs need to be scheduled on a machine
    with variable speed so as to optimize the flow-times of the jobs and
    the energy consumed by the machine. A series of results have
    culminated in constant-competitive algorithms for this problem in
    the clairvoyant model, i.e., when job parameters are revealed on
    releasing a job (Bansal, Pruhs, and Stein, SODA 2007; Bansal, Chan,
    and Pruhs, SODA 2009). Our main contribution in this paper is the
    first constant-competitive speed scaling algorithm in the non-
    clairvoyant model, which is typically used in the scheduling
    literature to model practical settings where job volume is revealed
    only after the job has been completely processed. Unlike in the
    clairvoyant model, the speed scaling problem in the non-clairvoyant
    model is non-trivial even for a single job. Our non-clairvoyant
    algorithm is defined by using the existing clairvoyant algorithm in
    a novel inductive way, which then leads to an inductive analytical
    tool that may be of independent interest for other online
    optimization problems. We also give additional algorithmic results
    and lower bounds for speed scaling on multiple identical parallel
    machines.
    :::
-   **Simple Auctions with Simple Strategies**
    \[[pdf](pubs/Draft-OneShot.pdf)\| [Show/Hide Abstract](#CP)\]\
    with Jamie Morgenstern, Vasilis Syrgkanis and Matt Weinberg. In
    Proc. *EC 2015*
    ::: {#absDA style="display:none"}
    We introduce single-bid auctions as a new format for combinatorial
    auctions. In single-bid auctions, each bidder submits a single
    real-valued bid for the right to buy items at a fixed price.
    Contrary to other simple auction formats, such as simultaneous or
    sequential single-item auctions, bidders can implement no-regret
    learning strategies for single-bid auctions in polynomial time.
    Price of anarchy bounds for correlated equilibria concepts in
    single-bid auctions therefore have more bite than their counterparts
    for auctions and equilibria for which learning is not known to be
    computationally tractable (or worse, known to be computationally
    intractable). Towards this end, we show that for any subadditive
    valuations the social welfare at equilibrium is an O(log m)
    approximation to the optimal social welfare, where m is the number
    of items. We also provide tighter approximation results for several
    subclasses. Our welfare guarantees hold for Nash equilibria and
    no-regret learning outcomes in both Bayesian and complete
    information settings via the smooth-mechanism framework. Of
    independent interest, our techniques show that in a combinatorial
    auction setting, efficiency guarantees of a mechanism via smoothness
    for a very restricted class ofcardinality it valuations extend, with
    a small degradation, to subadditive valuations, the largest
    complement-free class of valuations.
    :::
-   **Revenue Maximization and Ex-Post Budget Constraints**
    \[[pdf](pubs/Revenue%20Max%20Budget%20Constraints.pdf)\| [Show/Hide
    Abstract](#RMBC)\]\
    with Constantinos Daskalakis and Matt Weinberg. In Proc. *EC 2015*
    ::: {#absRMBC style="display:none"}
    We consider the problem of a revenue-maximizing seller with m items
    for sale to n additive bidders with hard budget constraints,
    assuming that the seller has some prior distribution over bidder
    values and budgets. The prior may be correlated across items and
    budgets of the same bidder, but is assumed independent across
    bidders. We target mechanisms that are Bayesian Incentive
    Compatible, but that are ex-post Individually Rational and ex-post
    budget respecting. Virtually no such mechanisms are known that
    satisfy all these conditions and guarantee any revenue
    approximation, even with just a single item. We provide a
    computationally efﬁcient mechanism that is a 3-approximation with
    respect to all BIC, ex-post IR, and ex-post budget respecting
    mechanisms. Note that the problem is NP-hard to approximate better
    than a factor of 16/15, even in the case where the prior is a point
    mass \[Chakrabarty and Goel 2010\]. We further characterize the
    optimal mechanism in this setting, showing that it can be
    interpreted as a distribution over virtual welfare maximizers. We
    prove our results by making use of a black-box reduction from
    mechanism to algorithm design developed by \[Cai et al. 2013\]. Our
    main technical contribution is a computationally efﬁcient
    3-approximation algorithm for the algorithmic problem that results
    by an application of their framework to this problem. The
    algorithmic problem has a mixed-sign objective and is NP-hard to
    optimize exactly, so it is surprising that a computationally
    efﬁcient approximation is possible at all. In the case of a single
    item (m = 1), the algorithmic problem can be solved exactly via
    exhaustive search, leading to a computationally efﬁcient exact
    algorithm and a stronger characterization of the optimal mechanism
    as a distribution over virtual value maximizers.
    :::
-   **Fast Algorithms for Online Stochastic Convex Programming**
    \[[pdf](pubs/ConvexSecretary.pdf)\|[Show/Hide Abstract](#FAOSCP)\]\
    with Shipra Agrawal. In Proc. *SODA 2015*
    ::: {#absFAOSCP style="display:none"}
    We introduce the online stochastic Convex Programming (CP) problem,
    a very general version of stochas- tic online problems which allows
    arbitrary concave objectives and convex feasibility constraints.
    Many well- studied problems like online stochastic packing and
    covering, online stochastic matching with concave returns, etc. form
    a special case of online stochastic CP. We present fast algorithms
    for these problems, which achieve near-optimal regret guarantees for
    both the i.i.d. and the random permutation models of stochastic
    inputs. When applied to the special case online packing, our ideas
    yield a simpler and faster primal-dual algorithm for this well
    studied problem, which achieves the optimal competitive ratio. Our
    techniques make explicit the connection of primal-dual paradigm and
    online learning to online stochastic CP.
    :::
-   **Perfect Bayesian Equilibria in Repeated Sales** \[[Arxiv
    pdf](http://arxiv.org/abs/1409.3062.pdf) \| [Show/Hide
    Abstract](#PBE)\]\
    with Yuval Peres and Balasubramanian Sivan. In Proc. *SODA 2015*
    ::: {#absPBE style="display:none"}
    A special case of Myerson\'s classic result describes the
    revenue-optimal equilibrium when a seller offers a single item to a
    buyer. We study a repeated sales extension of this model: a seller
    offers to sell a single fresh copy of an item to the same buyer
    every day via a posted price. The buyer\'s value for the item is
    unknown to the seller but is drawn initially from a publicly known
    distribution F and remains the same throughout. We study this
    setting where the seller is unable to commit to future prices and
    find several surprises. First, if the horizon is fixed, previous
    work showed that an equilibrium exists, and all equilibria yield
    tiny or constant revenue. This is a far cry from the linearly
    growing benchmark of getting Myerson optimal revenue each day. Our
    first result shows that this is because the buyer strategies in
    these equilibria are necessarily unnatural. We restrict to a natural
    class of buyer strategies called threshold strategies, and show that
    threshold equilibria rarely exist. Second, if the seller can commit
    not to raise prices upon purchase, while still retaining the
    possibility of lowering prices in future, we show that threshold
    equilibria always exist and for most distributions there is a unique
    threshold equilibrium. As an example, if F is uniform in \[0,1\],
    the seller can extract revenue of order \$\\sqrt{n}\$ in \$n\$
    rounds as opposed to the constant revenue obtainable when he is
    unable to make commitments. Finally, we consider the infinite
    horizon game, where both the seller and the buyer discount the
    future utility by a factor of \$1-\\delta \\in \[0,1)\$. When the
    value distribution is uniform in \[0,1\], there exists a threshold
    equilibrium with expected revenue at least \$\\frac{4}{3+2\\sqrt{2}}
    \\sim 69\$\\% of the Myerson optimal revenue benchmark. This is in
    sharp contrast to the constant revenue obtained in the limit of the
    \$n\$-stage games as \$n\$ approaches infinity.
    :::
-   **Budget Constraints in Prediction Markets**
    \[[pdf](pubs/ddhpuai15.pdf)\| [Show/Hide Abstract](#BCPM)\]\
    with Miro Dudik, Zhiyi Huang and Dave Pennock. In Proc. *UAI 2015*
    ::: {#absBCPM style="display:none"}
    An automated market maker is a natural and common mechanism to
    subsidize information acquisition, revelation, and aggregation in a
    prediction market. The sought-after prediction aggregate is the
    equilibrium price. However, traders with budget constraints are
    restricted in their ability to impact the market price on their own.
    We give a detailed characterization of optimal trades in the
    presence of budget constraints in a prediction market with a
    cost-function-based automated market maker. As a concrete
    application of our characterization, we give sufficient conditions
    for a property we call budget additivity: two traders with budgets B
    and B\' and the same beliefs would have a combined impact equal to a
    single trader with budget B +B\'. That way, even if a single trader
    cannot move the market much, a crowd of like-minded traders can have
    the same desired effect. We show that a generalization of the
    heavily-used logarithmic market scoring rule is budget additive for
    affinely independent payoffs, but the quadratic market scoring rule
    is not. Our results may be used both descriptively, to understand if
    a particular market maker is affected by budget constraints or not,
    and prescriptively, as a recipe to construct markets.
    :::

**2014**

-   **Envy freedom and prior-free mechanism design**
    \[[JET](http://www.sciencedirect.com/science/article/pii/S0022053114001094)
    \| [Arxiv pdf](http://arxiv.org/pdf/1212.3741.pdf) \| [Show/Hide
    Abstract](#EFPF)\]\
    with Jason D. Hartline and Qiqi Yan. In *Journal of Economic Theory,
    2014*
    ::: {#absEFPF style="display:none"}
    We consider the provision of an abstract service to
    single-dimensional agents. Our model includes position auctions,
    single-minded combinatorial auctions, and constrained matching
    markets. When the agents\' values are drawn independently from a
    distribution, the Bayesian optimal mechanism is given by Myerson as
    a virtual-surplus optimizer. We develop a framework for prior-free
    mechanism design and analysis. A good mechanism in our framework
    approximates the optimal mechanism for the distribution if there is
    a distribution; moreover, when there is no distribution this
    mechanism still provably performs well.\
    We define and characterize optimal envy-free outcomes in symmetric
    single-dimensional environments. Our characterization mirrors
    Myerson\'s theory. Furthermore, unlike in mechanism design where
    there is no point-wise optimal mechanism, there is always a
    point-wise optimal envy-free outcome.\
    Envy-free outcomes and incentive-compatible mechanisms are similar
    in structure and performance. We therefore use the optimal envy-free
    revenue as a benchmark for measuring the performance of a prior-free
    mechanism. A good mechanism is one that approximates the envy-free
    benchmark on any profile of agent values. We show that good
    mechanisms exist, and in particular, a natural generalization of the
    random sampling auction of Goldberg et al. is a constant
    approximation.
    :::
-   **Bandits with concave rewards and convex knapsacks** \[[Arxiv
    pdf](http://arxiv.org/pdf/1402.5758v1.pdf) \| [Show/Hide
    Abstract](#BwCR)\]\
    with Shipra Agrawal. In Proc. *ACM EC 2014*
    ::: {#absBwCR style="display:none"}
    In this paper, we consider a very general model for
    exploration-exploitation tradeoff which allows arbitrary concave
    rewards and convex constraints on the decisions across time, in
    addition to the customary limitation on the time horizon. This model
    subsumes the classic multi-armed bandit (MAB) model, and the Bandits
    with Knapsacks (BwK) model of Badanidiyuru et al.\[2013\]. We also
    consider an extension of this model to allow linear contexts,
    similar to the linear contextual extension of the MAB model. We
    demonstrate that a natural and simple extension of the UCB family of
    algorithms for MAB provides a polynomial time algorithm that has
    near-optimal regret guarantees for this substantially more general
    model, and matches the bounds provided by Badanidiyuru et
    al.\[2013\] for the special case of BwK, which is quite surprising.
    We also provide computationally more efficient algorithms by
    establishing interesting connections between this problem and other
    well studied problems/algorithms such as the Blackwell
    approachability problem, online convex optimization, and the
    Frank-Wolfe technique for convex optimization. We give examples of
    several concrete applications, where this more general model of
    bandits allows for richer and/or more efficient formulations of the
    problem.
    :::
-   **Removing Arbitrage from Wagering Mechanisms**
    \[[pdf](pubs/Wagering-full.pdf) \| [Show/Hide Abstract](#NAWM)\]\
    with Yiling Chen, David Pennock, Jennifer Wortman Vaughan. In Proc.
    *ACM EC 2014*
    ::: {#absNAWM style="display:none"}
    We observe that Lambert et al.\'s \[2008\] family of weighted score
    wagering mechanisms admit arbitrage: participants can extract a
    guaranteed positive payoﬀ by betting on any prediction within a
    certain range. In essence, participants leave free money on the
    table when they \"agree to disagree\", and as a result, rewards
    don't necessarily go to the most informed and accurate participants.
    This observation suggests that when participants have immutable
    beliefs, it may be possible to design alternative mechanisms in
    which the center can make a proﬁt by removing this arbitrage
    opportunity without sacriﬁcing incentive properties such as
    individual rationality, incentive compatibility, and sybilproofness.
    We introduce a new family of wagering mechanisms called no-arbitrage
    wagering mechanisms that retain many of the positive properties of
    weighted score wagering mechanisms, but with the arbitrage
    opportunity removed. We show several structural results about the
    class of mechanisms that satisfy no-arbitrage in conjunction with
    other properties, and provide examples of no-arbitrage wagering
    mechanisms with interesting properties.
    :::
-   **Primal dual gives optimal energy efficient online algorithms**
    \[[pdf](pubs/DH14-SODA.pdf) \| [Show/Hide Abstract](#DH14)\]\
    with Zhiyi Huang. In Proc. *SODA 2014*
    ::: {#absDH-14 style="display:none"}
    We consider the problem of online scheduling of jobs on unrelated
    machines with dynamic speed scaling to minimize the sum of energy
    and weighted flow time. We give an algorithm with an almost optimal
    competitive ratio for arbitrary power functions. (No earlier results
    handled arbitrary power functions for unrelated machines.) For power
    functions of the form \$f(s) = s\^\\alpha\$ for some constant
    \$\\alpha\>1\$, we get a competitive ratio of \$O(\\tfrac {\\alpha}
    {\\log \\alpha}) \$, improving upon a previous competitive ratio of
    \$O(\\alpha\^2)\$ by Anand et al., along with a matching lower bound
    of \$\\Omega(\\tfrac {\\alpha} {\\log \\alpha})\$. Further, in the
    resource augmentation model, with a 1+ \$\\epsilon\$ speed up, we
    give a \$2( \\tfrac 1 \\epsilon+1)\$ competitive algorithm, with
    essentially the same techniques, improving the bound of \$1 +
    O(\\frac{1}{\\epsilon\^2})\$ by Gupta et al. and matching the bound
    of Anand et al. for the special case of fixed speed unrelated
    machines. Unlike the previous results most of which used an
    amortized local competitiveness argument or dual fitting methods, we
    use a primal-dual method, which is useful not only to analyze the
    algorithms but also to design the algorithm itself.
    :::

**2013**

-   **Whole-page Optimization and Submodular Welfare Maximization with
    Online Bidders** \[[pdf](pubs/ec-free-disposal.pdf) \| [Show/Hide
    Abstract](#CP)\]\
    with Zhiyi Huang, Nitish Korula, Vahab Mirrokni and Qiqi Yan. In
    Proc. *ACM EC 2013*
    ::: {#absFD style="display:none"}
    In the context of online ad serving, display ads may appear on
    different types of web-pages, where each page includes several ad
    slots and therefore multiple ads can be shown on each page. The set
    of ads that can be assigned to ad slots of the same page needs to
    satisfy various pre-specified constraints including exclusion
    constraints, diversity constraints, and the like. Upon arrival of a
    user, the ad serving system needs to allocate a set of ads to the
    current web-page respecting these per-page allocation constraints.
    Previous slot-based settings ignore the important concept of a page,
    and may lead to highly suboptimal results in general. In this paper,
    motivated by these applications in display advertising and inspired
    by the submodular welfare maximization problem with online bidders,
    we study a general class of page-based ad allocation problems,
    present the first (tight) constant-factor approximation algorithms
    for these problems, and confirm the performance of our algorithms
    experimentally on real-world data sets. A key technical ingredient
    of our results is a novel primal-dual analysis for handling
    free-disposal, which updates dual variables using a \"level
    function\" instead of a single level, and unifies with previous
    analyses of related problems. This new analysis method allows us to
    handle arbitrarily complicated allocation constraints for each page.
    Our main result is an algorithm that achieves a 1 - 1/e - o(1)
    competitive ratio. Moreover, our experiments on real-world data sets
    show signi?cant improvements of our page-based algorithms compared
    to the slot-based algorithms. Finally, we observe that our problem
    is closely related to the submodular welfare maximization (SWM)
    problem. In particular, we introduce a variant of the SWM problem
    with online bidders, and show how to solve this problem using our
    algorithm for whole page optimization.
    :::
-   **Budget Smoothing for Internet Ad Auctions: A Game Theoretic
    Approach** \[[pdf](pubs/ec44-charles.pdf) \| [Show/Hide
    Abstract](#CP)\]\
    with Deeparnab Chakrabarty, Denis Charles, Max Chickering and Lei
    Wang. In Proc. *ACM EC 2013*
    ::: {#absBS style="display:none"}
    In Internet ad auctions, search engines often throttle budget
    constrained advertisers so as to spread their spends across the
    specified time period. Such policies are known as budget smoothing
    policies. In this paper, we perform a principled, game-theoretic
    study of what the outcome of an ideal budget smoothing algorithm
    should be. In particular, we propose the notion of regret-free
    budget smoothing policies whose outcomes throttle each advertiser
    optimally, given the participation of the other advertisers. We show
    that regret-free budget smoothing policies always exist, and in the
    case of single slot auctions we can give a polynomial time smoothing
    algorithm. Inspired by the existence proof, we design a heuristic
    for budget smoothing which performs considerably better than
    existing benchmark heuristics.
    :::
-   **Prior-free Auctions for Budgeted Agents**
    \[[pdf](pubs/ec14-devanur.pdf) \| [Show/Hide Abstract](#CP)\]\
    with Bach Q. Ha and Jason D. Hartline. In Proc. *ACM EC 2013*
    ::: {#absPFABA style="display:none"}
    We consider prior-free auctions for revenue and welfare maximization
    when agents have a common budget. The abstract environments we
    consider are ones where there is a downward-closed and symmetric
    feasibility constraint on the probabilities of service of the
    agents. These environments include position auctions where slots
    with decreasing click-through rates are auctioned to advertisers. We
    generalize and characterize the envy-free benchmark from Hartline
    and Yan \[2011\] to settings with budgets and characterize the
    optimal envy-free outcomes for both welfare and revenue. We give
    prior-free mechanisms that approximate these benchmarks. A building
    block in our mechanism is a clinching auction for position auction
    environments. This auction is a generalization of the multi-unit
    clinching auction of Dobzinski et al. \[2008\] and a special case of
    the polyhedral clinching auction of Goel et al. \[2012\]. For
    welfare maximization, we show that this clinching auction is a good
    approximation to the envy-free optimal welfare for position auction
    environments. For profit maximization, we generalize the random
    sampling profit extraction auction from Fiat et al. \[2002\] for
    digital goods to give a 10.0-approximation to the envy-free optimal
    revenue in symmetric, downward- closed environments. Even without
    budgets this revenue maximization question is of interest and we
    obtain an improved approximation bound of 7.5 (from 30.4 by Ha and
    Hartline \[2012\]).
    :::
-   **Tatonnement Beyond Gross Substitutes? Gradient Descent to the
    Rescue** \[[pdf](pubs/tatonnement-gradient-descent.pdf) \|
    [Show/Hide Abstract](#CP)\]\
    with Yun Kuen Cheung and Richard Cole. In Proc. *STOC 2013*. To
    appear in *GEB* .
    ::: {#absTAT style="display:none"}
    Tatonnement is a simple and natural rule for updating prices in
    Exchange (Arrow-Debreu) markets. In this paper we de- ?ne a class of
    markets for which tatonnement is equivalent to gradient descent.
    This is the class of markets for which there is a convex potential
    function whose gradient is always equal to the negative of the
    excess demand and we call it Convex Potential Function (CPF)
    markets. We show the following results.

    -   CPF markets contain the class of Eisenberg Gale (EG) markets,
        de?ned previously by Jain and Vazirani.
    -   The subclass of CPF markets for which the demand is a
        differentiable function contains exactly those mar- kets whose
        demand function has a symmetric negative semi-definite Jacobian.
    -   We de?ne a family of continuous versions of taton- nement based
        on gradient descent using a Bregman divergence. As we show, all
        processes in this family converge to an equilibrium for any CPF
        market. This is analogous to the classic result for markets
        satisfying the Weak Gross Substitutes property.
    -   A discrete version of tatonnement converges toward the
        equilibrium for the following markets of comple- mentary goods;
        its convergence rate for these settings is analyzed using a
        common potential function.
        -   Fisher markets in which all buyers have Leontief utilities.
            The tatonnement process reduces the distance to the
            equilibrium, as measured by the potential function, to an
            epsilon fraction of its initial value in O(1/epsilon) rounds
            of price updates.
        -   Fisher markets in which all buyers have comple- mentary CES
            utilities. Here, the distance to thequilibrium is reduced to
            epsilon fraction of its initial value in O(log(1/epsilon))
            rounds of price updates.

        This shows that tatonnement converges for the entire range of
        Fisher markets when buyers have complementary CES utilities, in
        contrast to prior work, which could analyze only the substitutes
        range, together with a small portion of the complementary range.
    :::
-   **Randomized Primal-Dual Analysis of RANKING for Online Bipartite
    Matching** \[[pdf](pubs/RPDFinal.pdf) \| [Show/Hide
    Abstract](#PR)\]\
    with Kamal Jain and Bobby Kleinberg. In Proc. *SODA 2013*
    ::: {#absKVV style="display:none"}
    We give a simple proof that the RANKING algorithm of Karp, Vazirani
    and Vazirani is 1-1/e competitive for the online bipartite matching
    problem. The proof is via a randomized primal-dual argument.
    Primal-dual algorithms have been successfully used for many online
    algorithm problems, but the dual constraints are always satisfied
    deterministically. This is the first instance of a non-trivial
    randomized primal-dual algorithm in which the dual constraints only
    hold in expectation. The approach also generalizes easily to the
    vertex-weighted version considered by Agarwal et al. Further we show
    that the proof is very similar to the deterministic primal-dual
    argument for the online budgeted allocation problem with small bids
    (also called the AdWords problem) of Mehta et al.
    :::

**2012**

-   **Asymptotically Optimal Algorithm for Stochastic Adwords**
    \[[pdf](pubs/AOASA.pdf) \| [Show/Hide Abstract](#PR)\]\
    with Balasubramanian Sivan and Yossi Azar. In Proc. *EC 2012*
    ::: {#absAOA style="display:none"}
    In this paper we consider the adwords problem in the *unknown
    distribution* model. We consider the case where the budget to bid
    ratio \$k\$ is at least 2, and give improved competitive ratios.
    Earlier results had competitive ratios better than \$1-1/e\$ only
    for \`\`large enough\'\' \$k\$, while our competitive ratio
    increases continuously with \$k\$. For \$k=2\$ the competitive ratio
    we get is \$0.729\$ and it is \$0.9\$ for \$k=16\$. We also improve
    the asymptotic competitive ratio for large \$k\$ from \$1 -
    O(\\sqrt{\\log n /k})\$ to \$1 - O(\\sqrt{1 /k})\$, thus removing
    any dependence on \$n\$, the number of advertisers. This ratio is
    optimal, even with known distributions. That is, even if an
    algorithm is tailored to the distribution, it cannot get a
    competitive ratio of \$1 - o(\\sqrt{1 /k})\$, whereas our algorithm
    does not depend on the distribution. The algorithm is rather simple,
    it computes a *score* for every advertiser based on his original
    budget, the remaining budget and the remaining number of steps in
    the algorithm and assigns a query to the advertiser with the highest
    bid plus his score. The analysis is based on a \`\`hybrid
    argument\'\' that considers algorithms that are part actual, part
    hypothetical, to prove that our (actual) algorithm is better than a
    completely hypothetical algorithm whose performance is easy to
    analyze.
    :::
-   **Online Matching with Concave Returns** \[[pdf](pubs/OMwCR.pdf) \|
    [Show/Hide Abstract](#PR)\]\
    with Kamal Jain. In Proc. *STOC 2012*
    ::: {#absCM style="display:none"}
    We consider a *significant* generalization of the Adwords problem by
    *allowing arbitrary concave returns, and we characterize the optimal
    competitive ratio achievable*. The problem considers a sequence of
    items arriving online that have to be allocated to agents, with
    different agents bidding different amounts. The objective function
    is the sum, over each agent i, of a monotonically non-decreasing
    concave function \$M\_i : R\_+ \\rightarrow R\_+\$ of the total
    amount allocated to i. All variants of online matching problems
    (including the Adwords problem) studied in the literature consider
    the special case of budgeted linear functions, that is, functions of
    the form \$M\_i( u\_i) = \\min \\{u\_i,B\_i\\}\$ for some constant
    \$B\_i\$. The distinguishing feature of this paper is in allowing
    arbitrary concave returns. The main result of this paper is that for
    each concave function \$M\$, there exists a constant \$F(M) \\leq
    1\$ such that

    -   there exists an algorithm with competitive ratio of
        \\\\\$\\min\_i\\{ F(M\_i) \\}\$, independent of the sequence of
        items.
    -   No algorithm has a competitive ratio larger than \$F(M)\$ over
        all instances with \$M\_i= M\$ for all \$i\$.

    Our algorithm is based on the primal-dual paradigm and makes use of
    convex programming duality. The upper bounds are obtained by
    formulating the task of finding the right counterexample as an
    optimization problem. This path takes us through the calculus of
    variations which deals with optimizing over continuous functions.
    The algorithm and the upper bound are related to each other via a
    set of differential equations, which points to a certain kind of
    duality between them.
    :::

**2011**

-   **Real-Time Bidding Algorithms for Performance-Based Display Ad
    Allocation** \[[pdf](pubs/rtb-perf.pdf)\| [Show/Hide
    Abstract](#PR)\]\
    with Ye Chen, Pavel Berkhin and Bo Anderson . In Proc. *KDD 2011*
    ::: {#absRTB style="display:none"}
    We describe a real-time bidding algorithm for performance-based
    display ad allocation. A central issue in performance display
    advertising is matching campaigns to ad impressions, which can be
    formulated as a constrained optimization problem that maximizes
    revenue subject to constraints such as budget limits and inventory
    availability. The current practice is to solve the optimization
    problem offline at a tractable level of impression granularity
    (e.g., the placement level), and to serve ads online based on the
    precomputed static delivery scheme. Although this offline approach
    takes a global view to achieve optimality, it fails to scale to ad
    delivery decision making at an individual impression level.
    Therefore, we propose a real-time bidding algorithm that enables
    fine-grained impression valuation (e.g., targeting users with
    real-time conversion data), and adjusts value-based bid according to
    real-time constraint snapshot (e.g., budget consumption level).
    Theoretically, we show that under a linear programming (LP)
    primal-dual formulation, the simple real-time bidding algorithm is
    indeed an online solver to the original primal problem by taking the
    optimal solution to the dual problem as input. In other words, the
    online algorithm guarantees the offline optimality given the same
    level of knowledge an offline optimization would have. Empirically,
    we develop and experiment with two real-time bid adjustment
    approaches to adapting to the non-stationary nature of the
    marketplace: one adjusts bids against real-time constraint
    satisfaction level using control-theoretic methods, and the other
    adjusts bids also based on the historical bidding landscape
    statistically modeled. Finally, we show experimental results with
    real-world ad serving data.
    :::
-   **Online Algorithms with Stochastic Input**
    \[[pdf](pubs/AdwordsStochastic.pdf) \]\
    In *ACM SIGEcom Exchanges, Vol. 10, No. 2, June 2011, Pages 40- 49.*
-   **Near Optimal Online Algorithms and Fast Approximation Algorithms
    for Resource Allocation Problems** \[[pdf](pubs/GWLfull.pdf) \|
    [Show/Hide Abstract](#PR)\]\
    with Kamal Jain, Balasubramanian Sivan and Christopher A. Wilkens In
    Proc. *ACM EC 2011*
    ::: {#absGWL style="display:none"}
    We present algorithms for a class of resource allocation problems
    both in the online setting with stochastic input and in the ofﬂine
    setting. This class of problems contains many interesting special
    cases such as the Adwords problem. In the online setting we
    introduce a new distributional model called the adversarial
    stochastic input model, which is a generalization of the i.i.d model
    with unknown distributions, where the distributions can change over
    time. In this model we give a 1 - O(epsilon) approximation algorithm
    for the resource allocation problem, with almost the weakest
    possible assumption: the ratio of the maximum amount of resource
    consumed by any single request to the total capacity of the
    resource, and the ratio of the proﬁt contributed by any single
    request to the optimal proﬁt is at most O (epsilon\^2
    /log(n/epsilon) where n is the number of resources available. There
    are instances where this ratio is epsilon\^2/log n such that no
    randomized algorithm can have a competitive ratio of 1 -
    o(epsilon\^2) even in the i.i.d model. The upper bound on ratio that
    we require improves on the previous upper-bound for the i.i.d case
    by a factor of n. Our proof technique also gives a very simple proof
    that the greedy algorithm has a competitive ratio of 1 - 1/e for the
    Adwords problem in the i.i.d model with unknown distributions, and
    more generally in the adversarial stochastic input model, when there
    is no bound on the bid to budget ratio. All the previous proofs
    assume that either bids are very small compared to budgets or
    something very similar to this. In the ofﬂine setting we give a fast
    algorithm to solve very large LPs with both packing and covering
    constraints. We give algorithms to approximately solve (within a
    factor of 1 + epsilon) the mixed packing-covering problem with
    O(gamma m log(n/delta)/epsilon\^2 ) oracle calls where the
    constraint matrix of this LP has dimension n x m, the success
    probability of the algorithm is 1 - delta, and gamma is a parameter
    which is very similar to the ratio described for the online setting.
    We discuss several applications, and how our algorithms improve
    existing results in some of these applications.
    :::
-   **Distributed Algorithms via Gradient Descent for Fisher Markets**
    \[[pdf](pubs/propresponse.pdf) \| [Show/Hide Abstract](#PR)\]\
    with Benjamin Birnbaum and Lin Xiao. In Proc. *ACM EC 2011*
    ::: {#absPR style="display:none"}
    Designing distributed algorithms that converge quickly to an equi-
    librium is one of the foremost research goals in algorithmic game
    theory, and convex programs have played a crucial role in the de-
    sign of algorithms for Fisher markets. In this paper we shed new
    light on both aspects for Fisher markets with linear and spending
    constraint utilities. We show fast convergence of the Proportional
    Response dynamics recently introduced by Wu and Zhang \[WZ07\]. The
    convergence is obtained from a new perspective: we show that the
    Proportional Response dynamics is equivalent to a gradient de- scent
    algorithm (with respect to a Bregman divergence instead of euclidean
    distance) on a convex program that captures the equilib- ria for
    linear utilities. We further show that the convex program program
    easily extends to the case of spending constraint utilities, thus
    resolving an open question raised by \[Vaz10\]. This also gives a
    way to extend the Proportional Response dynamics to spending
    constraint utilties. We also prove a technical result that is
    interest- ing in its own right: that the gradient descent algorithm
    based on a Bregman divergence converges with rate O(1/t) under a
    condition that is weaker than having Lipschitz continuous gradient
    (which is the usual assumption in the optimization literature for
    obtaining the same rate).
    :::

**2010**

-   **Fast Algorithms for Finding Matchings in Lopsided Bipartite Graphs
    with Applications to Display Ads** \[[pdf](pubs/waterlevel.pdf) \|
    [Show/Hide Abstract](#PR)\]\
    with Denis Charles, Max Chickering, Kamal Jain and Manan Sanghi. In
    Proc. *ACM EC 2010*
    ::: {#absWL style="display:none"}
    We derive efficient algorithms for both detecting and representing
    matchings in lopsided bipartite graphs; such graphs have so many
    nodes on one side that it is infeasible to represent them in memory
    or to identify matchings using standard approaches. Detecting and
    representing matchings in lopsided bipartite graphs is important for
    allocating and delivering guaranteed-placement display ads, where
    the corresponding bipartite graph of interest has nodes representing
    advertisers on one side and nodes representing web-page impressions
    on the other; real-world instances of such graphs can have billions
    of impression nodes. We provide theoretical guarantees for our
    algorithms, and in a real-world advertising application, we
    demonstrate the feasibility of our detection algorithms.
    :::
-   **Monotonicity in Bargaining Networks**
    \[[pdf](pubs/monotonicity.pdf) \| [Show/Hide Abstract](#MON)\]\
    with Yossi Azar, Kamal Jain and Yuval Rabani. In Proc. *SODA 2010*
    ::: {#absMON style="display:none"}
    We study bargaining networks, discussed in a recent paper of
    Kleinberg and Tardos, from the perspective of cooperative game
    theory. In particular we examine three solution concepts, the
    nucleolus, the core center and the core median. All solution
    concepts define unique solutions, so they provide testable
    predictions. We define a new monotonicity property that is a natural
    axiom of any bargaining game solution, and we prove that all three
    of them satisfy this monotonicity property. This is actually in
    contrast to the conventional wisdom for general cooperative games
    that monotonicity and the core condition (which is a basic property
    that all three of them satisfy) are incompatible with each other.
    Our proofs are based on a primal-dual argument (for the nucleolus)
    and on the FKG inequality (for the core center and the core median).
    We further observe some qualitative differences between the solution
    concepts. In particular, there are cases where a strict version of
    our monotonicity property is a natural axiom, but only the core
    center and the core median satisfy it. On the other hand, the
    nucleolus is easy to compute, whereas computing the core center or
    the core median is \#P-hard (yet it can be approximated in
    polynomial time).
    :::

**2009**

-   **Convergence of Local Dynamics to Balanced Outcomes in Exchange
    Networks** \[[pdf](pubs/edgebalancing.pdf) \| [Show/Hide
    Abstract](#EB)\]\
    with Yossi Azar, Benjamin Birnbaum, L. Elisa Celis and Yuval Peres.
    In Proc. *FOCS 2009*
    ::: {#absEB style="display:none"}
    Bargaining games on exchange networks have been studied by both
    economists and sociologists. A Balanced Out- come for such a game is
    an equilibrium concept that combines notions of stability and
    fairness. In a recent paper, Kleinberg and Tardos introduced
    balanced outcomes to the computer science community and provided a
    polynomial-time algorithm to compute the set of such outcomes. Their
    work left open a pertinent question: are there natural, local
    dynamics that converge quickly to a balanced outcome? In this paper,
    we provide a partial answer to this question by showing that simple
    edge- balancing dynamics converge to a balanced outcome whenever one
    exists.
    :::
-   **The Price of Truthfulness for Pay-Per-Click Auctions**
    \[[pdf](pubs/ppc.pdf) \| [Show/Hide Abstract](#PPC)\]\
    with Sham Kakade. In Proc. *ACM EC 2009.*
    ::: {#absPPC style="display:none"}
    We analyze the problem of designing a truthful pay-per-click auction
    where the click-through-rates (CTR) of the bidders are unknown to
    the auction. Such an auction faces the classic explore/exploit
    dilemma: while gathering information about the click through rates
    of advertisers, the mechanism may loose revenue; however, this
    gleaned information may prove valuable in the future for a more
    profitable allocation. In this sense, such mechanisms are prime
    candidates to be designed using multi-armed bandit techniques.
    However, a naive application of multi-armed bandit algorithms would
    not take into account the strategic considerations of the players
    \-\-- players might manipulate their bids (which determine the
    auction\'s revenue) in a way as to maximize their own utility.
    Hence, we consider the natural restriction that the auction be
    truthful. The revenue that we could hope to achieve is the expected
    revenue of a Vickrey auction that knows the true CTRs, and we define
    the truthful regret to be the difference between the expected
    revenue of the auction and this Vickrey revenue. This work sharply
    characterizes what regret is achievable, under a truthful
    restriction. We show that this truthful restriction imposes
    statistical limits on the achievable regret \-\-- the achievable
    regret is \$\\tilde{\\Theta}(T\^{2/3})\$, while for traditional
    bandit algorithms (without the truthful restriction) the achievable
    regret is \$\\tilde{\\Theta}(T\^{1/2})\$ (where \$T\$ is the number
    of rounds). We term the extra \$T\^{1/6}\$ factor, the \`price of
    truthfulness\'.
    :::
-   **The Adwords Problem: Online Keyword Matching with Budgeted Bidders
    under Random Permutations** \[[pdf](pubs/Adwords.pdf) \| [Show/Hide
    Abstract](#ADW)\]\
    with Tom Hayes. In Proc. *ACM EC 2009.*
    ::: {#absADW style="display:none"}
    We consider the problem of a search engine trying to assign a
    sequence of search keywords to a set of competing bidders, each with
    a daily spending limit. The goal is to maximize the revenue
    generated by these keyword sales, bearing in mind that, as some
    bidders may eventually exceed their budget, not all keywords should
    be sold to the highest bidder. We assume that the sequence of
    keywords (or equivalently, of bids) is revealed on-line. Our concern
    will be the competitive ratio for this problem versus the off-line
    optimum. We extend the current literature on this problem by
    considering the setting where the keywords arrive in a random order.
    In this setting we are able to achieve a competitive ratio of
    \$1-\\epsilon\$ under some mild, but necessary, assumptions. In
    contrast, it is already known that when the keywords arrive in an
    adversarial order, the best competitive ratio is bounded away from
    1. Our algorithm is motivated by PAC learning, and proceeds in two
    parts: a training phase, and an exploitation phase.
    :::
-   **Limited and Online Supply and the Bayesian foundations of
    prior-free mechanism design** \[[pdf](pubs/los.pdf) \| [Show/Hide
    Abstract](#LOS)\]\
    with Jason Hartline. In Proc. *ACM EC 2009.*
    ::: {#absLOS style="display:none"}
    We study auctions for selling a limited supply of a single commodity
    in the case where the supply is known in advance and the case it is
    unknown and must be instead allocated in an online fashion. The
    latter variant was proposed by Mahdian and Saberi as a model of an
    important phenomena in auctions for selling Internet advertising:
    advertising impressions must be allocated as they arrive and the
    total quantity available is unknown in advance. We describe the
    Bayesian optimal mechanism for these variants and extend the random
    sampling auction of Goldberg et al. to address the prior-free case.
    :::

::: {align="left"}
  --
  --

  ----------------------------
  [Other Publications]{#pub}
  ----------------------------

-   **A Unified Rounding Algorithm For Unrelated Machines Scheduling
    Problems.**\
    with Janardhan Kulkarni. In Proc. *SPAA 2018*.
    ::: {#absURA style="display:none"}
    :::
-   **A Rational Convex Program for Linear Arrow-Debreu Markets**
    \[[pdf](http://arxiv.org/pdf/1307.8037.pdf)\| [Show/Hide
    Abstract](#RCP)\]\
    with Jugal Garg and Laszlo A. Vegh . In *TEAC,* Volume 5 Issue 1,
    November 2016.
    ::: {#absRCP style="display:none"}
    We give a new, flow-type convex program describing equilibrium
    solutions to linear Arrow-Debreu markets. Whereas convex
    formulations were previously known \[Nenakov, Primak 83; Jain 07;
    Cornet \'89\], our program exhibits several new features. It gives a
    simple necessary and sufficient condition and a concise proof of the
    existence and rationality of equilibria, settling an open question
    raised by Vazirani. As a consequence we also obtain a simple new
    proof of Mertens\'s result that the equilibrium prices form a convex
    polyhedral set.
    :::
-   **On the Approximation of Submodular Functions**
    \[[pdf](http://arxiv.org/pdf/1307.8037.pdf)\| [Show/Hide
    Abstract](#ASM)\]\
    with Shaddin Dughmi, Roy Schwartz, Ankit Sharma and Mohit Singh.
    ::: {#absASM style="display:none"}
    Submodular functions are a fundamental object of study in
    combinatorial optimization, economics, machine learning, etc. and
    exhibit a rich combinatorial structure. Many subclasses of
    submodular functions have also been well studied and these
    subclasses widely vary in their complexity. Our motivation is to
    understand the relative complexity of these classes of functions.
    Towards this, we consider the question of how well can one class of
    submodular functions be approximated by another (simpler) class of
    submodular functions. Such approximations naturally allow algorithms
    designed for the simpler class to be applied to the bigger class of
    functions. We prove both upper and lower bounds on such
    approximations.\
    Our main results are:\
    1. General submodular functions can be approximated by cut functions
    of directed graphs to a factor of \$n\^2/4\$, which is tight.\
    2. General symmetric submodular functions\$\^{1}\$ can be
    approximated by cut functions of undirected graphs to a factor of
    \$n-1\$, which is tight up to a constant.\
    3. Budgeted additive functions can be approximated by coverage
    functions to a factor of \$e/(e-1)\$, which is tight.\
    Here \$n\$ is the size of the ground set on which the submodular
    function is defined.\
    We also observe that prior works imply that monotone submodular
    functions can be approximated by coverage functions with a factor
    between \$O(\\sqrt{n} \\log n)\$ and \$\\Omega(n\^{1/3} /\\log\^2 n)
    \$.
    :::
-   **Sequential Auctions of Identical Items with Budget-Constrained
    Bidders** \[[pdf](http://arxiv.org/pdf/1209.1698.pdf)\| [Show/Hide
    Abstract](#SAB)\]\
    with Zhiyi Huang and David Malec.
    ::: {#absSAB style="display:none"}
    In this paper, we study sequential auctions with two budget
    constrained bidders and any number of identical items. All prior
    results on such auctions consider only two items. We construct a
    canonical outcome of the auction that is the only natural
    equilibrium and is unique under a refinement of subgame perfect
    equilibria. We show certain interesting properties of this
    equilibrium; for instance, we show that the prices decrease as the
    auction progresses. This phenomenon has been observed in many
    experiments and previous theoretic work attributed it to features
    such as uncertainty in the supply or risk averse bidders. We show
    that such features are not needed for this phenomenon and that it
    arises purely from the most essential features: budget constraints
    and the sequential nature of the auction. A little surprisingly we
    also show that in this equilibrium one agent wins all his items in
    the beginning and then the other agent wins the rest. The major
    difficulty in analyzing such sequential auctions has been in
    understanding how the selling prices of the first few rounds affect
    the utilities of the agents in the later rounds. We tackle this
    difficulty by identifying certain key properties of the auction and
    the proof is via a joint induction on all of them.
    :::
-   **Cloud Scheduling with Setup Cost** \[[pdf](pubs/schedule6.pdf)\|
    [Show/Hide Abstract](#PR)\]\
    with Yossi Azar, Naama Ben-Aroya and Navendu Jain. In Proc. *SPAA
    2013*
    ::: {#absCSSC style="display:none"}
    In this paper, we investigate the problem of online task scheduling
    of jobs such as MapReduce jobs, Monte Carlo simulations and
    generating search index from web documents, on cloud computing
    infrastructures. We consider the virtualized cloud computing setup
    comprising machines that host multiple identical virtual machines
    (VMs) under pay-as-you-go charging, and that booting a VM requires a
    constant setup time. The cost of job computation depends on the
    number of VMs activated, and the VMs can be activated and shutdown
    on demand. We propose a new bi-objective algorithm to minimize the
    maximum task delay, and the total cost of the computation. We study
    both the clairvoyant case, where the duration of each task is known
    upon its arrival, and the more realistic non-clairvoyant case.
    :::
-   **Prior-Independent Multi-parameter Mechanism Design**
    \[[pdf](pubs/udca.pdf) \| [Show/Hide Abstract](#PR)\]\
    with Jason D. Hartline, Anna R. Karlin, C. Thach Nguyen In Proc.
    *WINE 2011*
    ::: {#absPIMD style="display:none"}
    In a multi-unit unit-demand multi-item auction, an auctioneer is
    selling a collection of different items to a set of agents each
    interested in buying at most unit. Each agent has a different
    private value for each of the items. We consider the problem of
    designing a truthful auction that maximizes the auctioneer\'s profit
    in this setting. Previously, there has been progress on this problem
    in the setting in which each value is drawn from a known prior
    distribution. Specifically, it has been shown how to design auctions
    tailored to these priors that achieve a constant factor
    approximation ratio profit. In this paper, we present the first
    prior-independent auction for this setting. This auction is
    guaranteed to achieve a constant fraction of the optimal expected
    profit for a large class of, so called, \`\`regular\'\'
    distributions, without specific knowledge of the distributions.
    :::
-   **An O(n log n) Algorithm for a Load Balancing Problem on Paths**
    \[[pdf](pubs/PathBalancing.pdf)\| [Show/Hide Abstract](#PR)\]\
    with Uri Feige. In Proc. *WADS 2011*
    ::: {#absPB style="display:none"}
    We study the following load balancing problem on paths (PB). There
    is a path containing n vertices. Every vertex i has an initial load
    h i , and every edge (j, j + 1) has an initial load w j that it
    needs to distribute among the two vertices that are its endpoints.
    The goal is to distribute the load of the edges over the vertices in
    a way that will make the loads of the vertices as balanced as
    possible (formally, mini- mizing the sum of squares of loads of the
    vertices). This problem can be solved in polynomial time, e.g, by
    dynamic programming. We present an algorithm that solves this
    problem in time O(n log n). As a mental aide in the design of our
    algorithm, we ﬁrst design a hy- draulic apparatus composed of bins
    (representing vertices), tubes (rep- resenting edges) that are
    connected between bins, cylinders within the tubes that constrain
    the ﬂow of water, and valves that can close the con- nections
    between bins and tubes. Water may be poured into the various bins,
    to levels that correspond to the initial loads in the input to the
    PB problem. When all valves are opened, the water ﬂows between bins
    (to the extent that is feasible due to the cylinders) and stabilizes
    at levels that are the correct output to the respective PB problem.
    Our algorithm is based on a fast simulation of the behavior of this
    hydraulic apparatus, when valves are opened one by one.
    :::
-   **Local Dynamics in Bargaining Networks via Random-Turn Games**
    \[[pdf](pubs/BargainingRTG.pdf)\| [Show/Hide Abstract](#PR)\]\
    with Elisa Celis and Yuval Peres. In Proc. *WINE 2010*
    ::: {#absRTG style="display:none"}
    We present a new technique for analyzing the rate of convergence of
    local dynamics in bargaining networks. The technique reduces
    balancing in a bargaining network to optimal play in a random-turn
    game. We analyze this game using techniques from martingale and
    Markov chain theory. We obtain a tight polynomial bound on the rate
    of convergence for a nontrivial class of unweighted graphs (the
    previous known bound was exponential). Additionally, we show this
    technique extends naturally to many other graphs and dynamics.
    :::
-   **Market Equilibrium with Transaction Costs**
    \[[pdf](pubs/mewtc.pdf)\| [Show/Hide Abstract](#PR)\]\
    with Sourav Chakraborty and Chinmay Karande. In Proc. *WINE 2010*
    ::: {#absMEWTC style="display:none"}
    Identical products being sold at different prices in different
    locations is a common phenomenon. To model such scenarios, we
    supplement the classical Fisher market model by introducing {\\em
    transaction costs}. For every buyer \$i\$ and good \$j\$, there is a
    transaction cost of \$c\_{ij}\$; if the price of good \$j\$ is
    \$p\_j\$, then the cost to the buyer \$i\$ {\\em per unit} of \$j\$
    is \$p\_j + c\_{ij}\$. The same good can thus be sold at different
    (effective) prices to different buyers. We provide a combinatorial
    algorithm that computes \$\\epsilon\$-approximate equilibrium prices
    and allocations in
    \$O\\left(\\frac{1}{\\epsilon}(n+\\log{m})mn\\log(B/\\epsilon)\\right)\$
    operations - where \$m\$ is the number goods, \$n\$ is the number of
    buyers and \$B\$ is the sum of the budgets of all the buyers.
    :::
-   **An Online Multi-unit Auction with Improved Competitive Ratio**
    \[[pdf](pubs/OMUA.pdf) \| [Show/Hide Abstract](#OMUA)\]\
    with Sourav Chakraborty. In Proc. *WINE 2009.*
    ::: {#absOMUA style="display:none"}
    We improve the best known competitive ratio (from 1/4 to 1/2), for
    the online multi-unit allocation problem, where the objective is to
    maximize the single-price revenue. Moreover, the competitive ratio
    of our algorithm tends to 1, as the bid-profile tends to
    \"smoothen\". This algorithm is used as a subroutine in designing
    truthful auctions for the same setting: the allocation has to be
    done online, while the payments can be decided at the end of the
    day. Earlier, a reduction from the auction design problem to the
    allocation problem was known only for the unit-demand case. We give
    a reduction for the general case when the bidders have decreasing
    marginal utilities. The problem is inspired by sponsored search
    auctions.
    :::
-   **A Computational Theory of Awareness and Decision Making**
    \[[pdf](pubs/awareness.pdf) \| [Show/Hide Abstract](#AWA)\]\
    with Lance Fortnow. In Proc. *Theoretical Aspects of Rationality and
    Knowledge, TARK 2009*
    ::: {#absAWA style="display:none"}
    We exhibit a new computational-based definition of awareness,
    informally that our level of unawareness of an object is the amount
    of time needed to generate that object within a certain environment.
    We give several examples to show this notion matches our intuition
    in scenarios where one organizes, accesses and transfers
    information. We also give a formal process-independent definition of
    awareness based on Levin\'s universal enumeration. We show the
    usefulness of computational awareness by showing how it relates to
    decision making, and how others can manipulate our decision making
    with appropriate advertising, in particular, we show connections to
    sponsored search and brand awareness. Understanding awareness can
    also help rate the effectiveness of various user interfaces designed
    to access information.
    :::
-   **Market Equilibria in Polynomial time for fixed number of goods or
    agents** \[[pdf](pubs/PLC.pdf) \| [Show/Hide Abstract](#PLC)\]\
    with Ravi Kannan. In Proc. *FOCS 2008.*
    ::: {#absPLC style="display:none"}
    We consider markets in the classical Arrow-Debreu model. There are n
    agents and m goods. Each buyer has a concave utility function (of
    the bundle of goods he/she buys) and an initial bundle. At an
    \`\`equilibrium\'\' set of prices for goods, if each individual
    buyer separately exchanges the initial bundle for an optimal bundle
    at the set prices, the market clears, i.e., all goods are exactly
    consumed. Classical theorems guarantee the existence of equilibria,
    but computing them has been the subject of much recent research. In
    the related area of Multi-Agent Games, much attention has been paid
    to the complexity as well as algorithms. While most general problems
    are hard, polynomial time algorithms have been developed for
    restricted classes of games, when one assumes the number of
    strategies is constant.

    For the Market Equilibrium problem, several important special cases
    of utility functions have been tackled. Here we begin a program for
    this problem similar to that for multi-agent games, where general
    utilities are considered. We begin by showing that if the utilities
    are separable piece-wise linear concave (PLC) functions, and the
    number of goods (or alternatively the number of buyers) is constant,
    then we can compute an exact equilibrium in polynomial time. Our
    technique for the constant number of goods is to decompose the space
    of price vectors into cells using certain hyperplanes, so that in
    each cell, each buyer\'s threshold marginal utility is known. Still,
    one needs to solve a linear optimization problem in each cell. We
    then show the main result - that for general (non-separable) PLC
    utilities, an exact equilibrium can be found in polynomial time
    provided the number of goods is constant. The starting point of the
    algorithm is a \`\`cell-decomposition\'\' of the space of price
    vectors using polynomial surfaces (instead of hyperplanes). We use
    results from computational algebraic geometry to bound the number of
    such cells. For solving the problem inside each cell, we introduce
    and use a novel LP-duality based method. We note that if the number
    of buyers and agents both can vary, the problem is PPAD hard even
    for the very special case of PLC utilities such as Leontief
    utilities and separable PLC utilities.
    :::
-   **New Geometry-Inspired Relaxations and Algorithms for the Metric
    Steiner Tree Problem.** \[[pdf](pubs/steiner.pdf) \| [Show/Hide
    Abstract](#STI)\]\
    with Deeparnab Chakrabarty, and Vijay Vazirani. In *Math Programming
    (Series A)* Volume 122, Number 2 (April 2010). (Preliminary version
    in *IPCO 2008.* )
    ::: {#absSTI style="display:none"}
    Determining the integrality gap of the bidirected cut relaxation for
    the metric Steiner tree problem, and exploiting it algorithmically,
    is a long-standing open problem. We use geometry to define an LP
    whose dual is equivalent to this relaxation. This opens up the
    possibility of using the primal-dual schema in a geometric setting
    for designing an algorithm for this problem. Using this approach, we
    obtain a 4/3 factor algorithm and integrality gap bound for the case
    of quasi-bipartite graphs; the previous best integrality gap upper
    bound being 3/2. We also obtain a factor \$sqrt{2}\$ strongly
    polynomial algorithm for this class of graphs. A key difficulty
    experienced by researchers in working with the bidirected cut
    relaxation was that any reasonable dual growth procedure produces
    extremely unwieldy dual solutions. A new algorithmic idea helps
    finesse this difficulty - that of reducing the cost of certain edges
    and constructing the dual in this altered instance - and this idea
    can be extracted into a new technique for running the primal-dual
    schema in the setting of approximation algorithms.
    :::
-   **On Computing the Distinguishing Numbers of Planar Graphs and
    Beyond: a Counting Approach** \[[pdf](pubs/dist.pdf) \| [Show/Hide
    Abstract](#DIST)\]\
    with V. Arvind and Christine Cheng. In *SIAM Journal on Discrete
    Mathematics,* vol. 22, no. 4 (October 2008), pp. 1297-1324.
    ::: {#absDIST style="display:none"}
    A vertex k-labeling of graph G is distinguishing if the only
    automorphism that preserves the labels of G is the identity map. The
    distinguishing number of G, D(G), is the smallest integer k for
    which G has a distinguishing k-labeling. In this paper, we apply the
    principle of inclusion-exclusion and develop recursive formulas to
    count the number of inequivalent distinguishing k-labelings of a
    graph. Along the way, we prove that the distinguishing number of a
    planar graph can be computed in time polynomial in the size of the
    graph.
    :::
-   **On the Equivalence of Competitive and Submodular markets**
    \[[pdf](pubs/competitive.pdf) \| [Show/Hide Abstract](#COM)\]\
    with Deeparnab Chakrabarty. In *Operations Research Letters,* vol.
    37, no. 3, pp. 155 - 158, 2009. Prelim. version in Proc. *WINE 2007*
    ::: {#absCOM style="display:none"}
    In this paper, we study competitive markets - a market is
    competitive if increasing the endowment of any one buyer does not
    in- crease the equilibrium utility of any other buyer. In the Fisher
    setting, competitive markets contain all markets with weak gross
    substitutabil- ity (WGS), a property which enable efficient
    algorithms for equilibrium computation. We show that every uniform
    utility allocation (UUA) market which is competitive, is a
    submodular utility allocation (SUA) market. Our result provides
    evidence for the existence of efficient algoritheorems for the class
    of competitive markets.
    :::
-   **Computing Market Equilibrium: Beyond Weak Gross Substitutes**
    \[[pdf](pubs/ApproxWGS.pdf) \| [Show/Hide Abstract](#AWGS)\]\
    with Chinmay Karande. In Proc. *WINE 2007*
    ::: {#absAWGS style="display:none"}
    The property of Weak Gross Substitutibility (WGS) of goods in a
    market has been found to be conducive to efficient algorithms for
    finding equilibria. In this paper, we give a natural definition of a
    \$\\delta\$ approximate WGS property, and show that the auction
    algorithm of Garg and Kapoor can be extended to give an
    \$\\epsilon + \\delta\$ approximate equilibrium for markets with
    this property.
    :::
-   **New results on Rationality and Strongly Poylnomial Solvability in
    Eisenberg-Gale markets** \[[pdf](pubs/EG2.pdf) \| [Show/Hide
    Abstract](#EG2)\]\
    with Deeparnab Chakrabarty and Vijay Vazirani. In Proc. *WINE 2006*
    ::: {#absEG2 style="display:none"}
    We study the structure of EG(2) markets, the class of Eisenberg-Gale
    markets with two agents. We prove that all markets in this class are
    rational and they admit strongly polynomial algorithms whenever the
    polytope containing the set of feasible utilities of the two agents
    can be described via a combinatorial LP. This helps resolve
    positively the status of two markets left as open problems by Jain
    and Vazirani: the capacity allocation market in a directed graph
    with two source-sink pairs and the network coding market in a
    directed network with two sources. Our algorithms for solving the
    corresponding nonlinear convex programs are fundamentally different
    from those obtained by Jain and Vazirani; whereas they use the
    primal- dual schema, we use a carefully constructed binary search.
    :::
-   **Integrality Gaps for Sparsest Cut and Minimum Linear Arrangement
    Problems** \[[pdf](pubs/usc.pdf) \| [Show/Hide Abstract](#USC)\]\
    with Subhash A. Khot, Rishi Saket and Nisheeth K. Vishnoi. In Proc.
    *STOC 2006.*
    ::: {#absUSC style="display:none"}
    Arora, Rao and Vazirani showed that the standard semi-definite
    programming (SDP) relaxation of the sparsest cut problem with the
    triangle inequality constraints has an integrality gap of
    \$O(\\sqrt{\\log n})\$. They conjectured that the gap is bounded
    from above by a constant. In this paper, we disprove this conjecture
    by constructing an \$\\Omega(\\log \\log n)\$ integrality gap
    instance. Khot and Vishnoi had earlier disproved the non-uniform
    version of this Conjecture. A simple \`\`stretching\'\' of the
    integrality gap instance for the sparsest cut problem serves as an
    \$\\Omega(\\log \\log n)\$ integrality gap instance for the SDP
    relaxation of the Minimum Linear Arrangement problem. This SDP
    relaxation was considered in Charikar et. al. and Feige and Lee,
    where it was shown that its integrality gap is bounded from above by
    \$O(\\sqrt{\\log n} \\log \\log n).\$
    :::
-   **Price of Anarchy, Locality Gap, and a Network Service Provider
    Game** \[[pdf](pubs/POA.pdf) \| [Show/Hide Abstract](#POA)\]\
    with Naveen Garg, Rohit Khandekar, Vinayaka Pandit, Amin Saberi, and
    Vijay V. Vazirani. In Proc. *WINE 2005*
    ::: {#absPOA style="display:none"}
    In this paper, we define a network service provider game. We show
    that the price of anarchy of the defined game can be bounded by
    analyzing a local search heuristic for a related facility location
    problem called the \$k\$-facility location problem. As a result, we
    show that the \$k\$-facility location problem has a locality gap
    of 5. This result is of interest on its own. Our result gives
    evidence to the belief that the price of anarchy of certain games
    are related to analysis of local search heuristics.
    :::
-   **On the complexity of Hilbert\'s 17th problem**
    \[[pdf](pubs/hilbert.pdf) \| [Show/Hide Abstract](#HIL)\]\
    with Richard J. Lipton and Nisheeth Vishnoi. In Proc. *FSTTCS 2004.*
    ::: {#absHIL style="display:none"}
    Hilbert posed the following problem as the 17th in the list of 23
    problems in his famous 1900 lecture: *Given a multivariate
    polynomial that takes only non-negative values over the reals, can
    it be represented as a sum of squares of rational functions?* In
    1927, E.\~Artin gave an affirmative answer to this question. His
    result guaranteed the existence of such a finite representation and
    raised the following important question: *What is the {\\bf minimum
    number} of rational functions needed to represent any non-negative
    \$n\$-variate, degree \$d\$ polynomial?* In 1967, Pfister proved
    that any \$n\$-variate non-negative polynomial over the reals can be
    written as sum of squares of at most \$2\^n\$ rational functions. In
    spite of a considerable effort by mathematicians for over 75 years,
    it is *not* known whether \$n+2\$ rational functions are sufficient!
    In lieu of the lack of progress towards the resolution of this
    question, we initiate the study of Hilbert\'s 17th problem from the
    point of view of Computational Complexity. In this setting, the
    following question is a natural relaxation: *What is the {\\bf
    descriptive complexity} of the sum of squares representation (as
    rational functions) of a non-negative, \$n\$-variate, degree \$d\$
    polynomial?* We consider arithmetic circuits as a natural
    representation of rational functions. We are able to show, assuming
    a standard conjecture in complexity theory, that it is impossible
    that every non-negative, \$n\$-variate, degree four polynomial can
    be represented as a sum of squares of a small (polynomial in \$n\$)
    number of rational functions, each of which has a small size
    arithmetic circuit (over the rationals) computing it.

    Our result points to the direction that it is unlikely that every
    non-negative, \$n\$-variate polynomial over the reals can be written
    as a sum of squares of a polynomial (in \$n\$) number of rational
    functions. Further, relating to standard (and believed to be hard to
    prove) complexity-theoretic conjectures sheds some light on why it
    has been difficult for mathematicians to close the \$n+2\$ and
    \$2\^n\$ gap. We hope that our line of work will play an important
    role in the resolution of this question.
    :::
-   **The Spending Constraint Model for Market Equilibrium: Algorithmic,
    Existence and Uniqueness results** \[[pdf](pubs/sconstraint.pdf) \|
    [Show/Hide Abstract](#SC)\]\
    with Vijay V. Vazirani. In Proc. *STOC 2004.*
    ::: {#absSC style="display:none"}
    The traditional model of market equilibrium supports impressive
    existence results, including the celebrated Arrow-Debreu Theorem.
    However, in this model, polynomial time algorithms for computing (or
    approximating) equilibria are known only for linear utility
    functions. We present a new, and natural, model of market
    equilibrium that not only admits existence and uniqueness results
    paralleling those for the traditional model but is also amenable to
    efficient algorithms.
    :::
-   **An Improved Approximation Scheme for Computing Arrow-Debreu Prices
    for the Linear Case** \[[pdf](pubs/adptas.pdf) \| [Show/Hide
    Abstract](#AD)\]\
    with Vijay Vazirani. In Proc. *FSTTCS 2003.*
    ::: {#absAD style="display:none"}
    Recently, Jain, Mahdian and Saberi had given a FPTAS for the problem
    of computing a market equilibrium in the Arrow-Debreu setting, when
    the utilities are linear functions. Their running time depended on
    the size of the numbers representing the utilities and endowments of
    the buyers. In this paper, we give a strongly polynomial time
    approximation scheme for this problem. Our algorithm builds upon the
    main ideas behind the algorithm in Devanur et. al.
    :::
-   **Strategyproof cost-sharing Mechanisms for Set Cover and Facility
    Location Games** \[[pdf](pubs/DMV.pdf) \| [Show/Hide
    Abstract](#DMV)\]\
    with Milena Mihail and Vijay Vazirani. *Decision Support Systems* 39
    (March 2005), pp 11\--22. Prelim. version in Proc. *ACM EC 2003*
    ::: {#absDMV style="display:none"}
    Strategyproof cost-sharing mechanisms, lying in the core, that
    recover \$1/\\alpha\$ fraction of the cost, are presented for the
    set cover and facility location games; \$\\alpha = O(\\log n)\$ for
    the former and 1.861 for the latter. Our mechanisms utilize
    approximation algorithms for these problems based on the method of
    dual-fitting.
    :::
-   **Market Equilibrium via a Primal-Dual-Type Algorithm**
    \[[pdf](pubs/DPSV-JACM.pdf) \| [Show/Hide Abstract](#DPSV)\]\
    with Christos H. Papadimitriou, Amin Saberi and Vijay V.Vazirani. In
    The *Journal of the ACM*, vol. 55, no. 5 (October 2008), pp 1\--18.
    Prelim version appeared in *FOCS 2002.*
    ::: {#absDPSV style="display:none"}
    We give the first polynomial time algorithm for exactly computing an
    equilibrium for the linear utilities case of the market model
    defined by Fisher. Our algorithm uses the primal-dual paradigm in
    the enhanced setting of KKT conditions and convex programs. We
    pinpoint the added difficulty raised by this setting and the manner
    in which our algorithm circumvents it.
    :::
:::
